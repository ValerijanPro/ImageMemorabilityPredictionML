{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e0ac92-9d90-4356-b35d-2ebf6977985b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newest best accuracy:  0.42857142857142855\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest top3 best accuracy:  0.60317462682724\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.3903174603174603\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.41111111111111115\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.41111111111111115\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  1\n",
      "Newest best accuracy:  0.5396825396825397\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest top3 best accuracy:  0.7142857313156128\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.47968253968253965\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5166666666666667\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5166666666666667\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  2\n",
      "Newest f1 best accuracy:  0.5169047619047619\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5388888888888889\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5388888888888889\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  3\n",
      "Newest best accuracy:  0.5714285714285714\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest top3 best accuracy:  0.761904776096344\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.5346825396825395\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5611111111111111\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5611111111111111\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  4\n",
      "Current:  5\n",
      "Newest best accuracy:  0.6031746031746031\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.5566666666666666\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5777777777777777\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5777777777777777\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  6\n",
      "Current:  7\n",
      "Current:  8\n",
      "Current:  9\n",
      "Current:  10\n",
      "Current:  11\n",
      "Current:  12\n",
      "Newest f1 best accuracy:  0.5647619047619048\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5944444444444444\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5944444444444444\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  13\n",
      "Current:  14\n",
      "Current:  15\n",
      "Current:  16\n",
      "Newest top3 best accuracy:  0.7777777910232544\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  17\n",
      "Current:  18\n",
      "Current:  19\n",
      "Current:  20\n",
      "Newest top3 best accuracy:  0.8253968358039856\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  21\n",
      "Current:  22\n",
      "Current:  23\n",
      "Current:  24\n",
      "Current:  25\n",
      "Current:  26\n",
      "Current:  27\n",
      "Current:  28\n",
      "Current:  29\n",
      "Current:  30\n",
      "Current:  31\n",
      "Current:  32\n",
      "Current:  33\n",
      "Current:  34\n",
      "Current:  35\n",
      "Current:  36\n",
      "Current:  37\n",
      "Current:  38\n",
      "Current:  39\n",
      "Current:  40\n",
      "Current:  41\n",
      "Current:  42\n",
      "Current:  43\n",
      "Current:  44\n",
      "Current:  45\n",
      "Current:  46\n",
      "Current:  47\n",
      "Current:  48\n",
      "Current:  49\n",
      "Current:  50\n",
      "Newest best accuracy:  0.6507936507936508\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.6072222222222223\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.65\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.65\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  51\n",
      "Current:  52\n",
      "Current:  53\n",
      "Current:  54\n",
      "Current:  55\n",
      "Current:  56\n",
      "Current:  57\n",
      "Current:  58\n",
      "Current:  59\n",
      "Current:  60\n",
      "Current:  61\n",
      "Current:  62\n",
      "Newest f1 best accuracy:  0.61\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  63\n",
      "Current:  64\n",
      "Current:  65\n",
      "Current:  66\n",
      "Current:  67\n",
      "Current:  68\n",
      "Current:  69\n",
      "Current:  70\n",
      "Current:  71\n",
      "Current:  72\n",
      "Current:  73\n",
      "Current:  74\n",
      "Current:  75\n",
      "Current:  76\n",
      "Current:  77\n",
      "Current:  78\n",
      "Current:  79\n",
      "Current:  80\n",
      "Current:  81\n",
      "Current:  82\n",
      "Current:  83\n",
      "Current:  84\n",
      "Current:  85\n",
      "Current:  86\n",
      "Current:  87\n",
      "Current:  88\n",
      "Current:  89\n",
      "Current:  90\n",
      "Current:  91\n",
      "Current:  92\n",
      "Current:  93\n",
      "Current:  94\n",
      "Current:  95\n",
      "Current:  96\n",
      "Current:  97\n",
      "Current:  98\n",
      "Current:  99\n",
      "Current:  100\n",
      "Current:  101\n",
      "Current:  102\n",
      "Current:  103\n",
      "Current:  104\n",
      "Current:  105\n",
      "Current:  106\n",
      "Current:  107\n",
      "Current:  108\n",
      "Current:  109\n",
      "Current:  110\n",
      "Current:  111\n",
      "Current:  112\n",
      "Current:  113\n",
      "Current:  114\n",
      "Current:  115\n",
      "Current:  116\n",
      "Current:  117\n",
      "Current:  118\n",
      "Current:  119\n",
      "Current:  120\n",
      "Current:  121\n",
      "Current:  122\n",
      "Current:  123\n",
      "Current:  124\n",
      "Current:  125\n",
      "Current:  126\n",
      "Current:  127\n",
      "Current:  128\n",
      "Current:  129\n",
      "Current:  130\n",
      "Current:  131\n",
      "Current:  132\n",
      "Current:  133\n",
      "Current:  134\n",
      "Current:  135\n",
      "Current:  136\n",
      "Current:  137\n",
      "Current:  138\n",
      "Current:  139\n",
      "Current:  140\n",
      "Current:  141\n",
      "Current:  142\n",
      "Current:  143\n",
      "Current:  144\n",
      "Current:  145\n",
      "Current:  146\n",
      "Current:  147\n",
      "Current:  148\n",
      "Current:  149\n",
      "Current:  150\n",
      "FINAL Best accuracy:  0.6507936507936508\n",
      "FINAL Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import collections\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, balanced_accuracy_score\n",
    "import gc\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "sigmas = [1]\n",
    "#grid_sizes = [(20, 20), (30, 30), (40, 40),(50, 50), (60, 60)]\n",
    "grid_sizes = [(30, 30)]\n",
    "#gaussian_sizes = [(1, 1), (19, 19), (35, 35), (43, 43)]\n",
    "gaussian_sizes = [(43, 43)]\n",
    "#batch_sizes = [32, 48, 128, 176]\n",
    "batch_sizes = [128]\n",
    "dropouts = [0.5]\n",
    "#reg_terms = [0.001, 0.0001]\n",
    "reg_terms = [0.0001]\n",
    "learning_rates = [1e-3]\n",
    "patiences = [30]\n",
    "min_lrs = [1e-6]\n",
    "factors = [0.2]\n",
    "#test_sizes = [0.1, 0.15, 0.2]\n",
    "test_sizes = [0.1]\n",
    "results_folder = \"MODELS COMPARISON\"\n",
    "\n",
    "options =\n",
    "\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_top3_accuracy = 0\n",
    "best_f1_accuracy = 0\n",
    "best_per_class_accuracy = 0\n",
    "best_balanced_accuracy = 0\n",
    "best_params = {}\n",
    "best_params_top3 = {}\n",
    "best_params_f1 = {}\n",
    "best_params_per_class = {}\n",
    "best_params_balanced_accuracy = {}\n",
    "                                            \n",
    "distance = 610\n",
    "h_res = 1920\n",
    "v_res = 1080\n",
    "screen_w = 527\n",
    "screen_h = 296\n",
    "\n",
    "current = 0\n",
    "\n",
    "                                            \n",
    "                                            \n",
    "\n",
    "def compute_ppda(distance, h_res, v_res, screen_w, screen_h):\n",
    "    \"\"\"\n",
    "    Compute the number of pixels per degree of visual angle based on the experimental conditions.\n",
    "    \n",
    "    :param distance: int, the distance between the observer and the screen (in mm)\n",
    "    :param h_res: int, the horizontal resolution of the screen\n",
    "    :param v_res: int, the vertical resolution of the screen\n",
    "    :param screen_w: int, the width of the screen (in mm)\n",
    "    :param screen_h: int, the height of the screen (in mm)\n",
    "    :return horizontal_ppda: float, the number of pixel per degree of visual angle\n",
    "    \"\"\"\n",
    "    pxl_density_x = h_res / screen_w\n",
    "    pxl_density_y = v_res / screen_h\n",
    "    \n",
    "    d = 2 * distance * math.tan(np.deg2rad(0.5))\n",
    "    horizontal_ppda = d * ((pxl_density_x + pxl_density_y) / 2)\n",
    "    \n",
    "    return horizontal_ppda\n",
    "                                            \n",
    "ppda = compute_ppda(distance, h_res, v_res, screen_w, screen_h)\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    for sigma in sigmas:\n",
    "        for factor in factors:\n",
    "            for gaussian_size in gaussian_sizes:\n",
    "                for batch_size in batch_sizes:\n",
    "                    for dropout in dropouts:\n",
    "                        for reg_term in reg_terms:\n",
    "                            for lr in learning_rates:\n",
    "                                for patience in patiences:\n",
    "                                    for min_lr in min_lrs:\n",
    "                                        for grid_size in grid_sizes:\n",
    "\n",
    "                                            def checkObserverRemembered(observer, image_path, base_dir):\n",
    "                                                csv_file_path = os.path.join(base_dir, \"..\" ,\"hit_status.csv\")\n",
    "                                                if not os.path.isfile(csv_file_path):\n",
    "                                                    print(\"Error: CSV file not found.\")\n",
    "                                                    return False\n",
    "                                                df = pd.read_csv(csv_file_path)\n",
    "                                                filtered_rows = df[(df['Setup Folder'] == observer) & (df['Image Path'] == image_path) & (df['Hit'] == 1)]\n",
    "                                                if not filtered_rows.empty:\n",
    "                                                    return True\n",
    "                                                else:\n",
    "                                                    return False\n",
    "\n",
    "                                            def bin_fixations(fixation_map):\n",
    "                                                global grid_size\n",
    "                                                height, width = fixation_map.shape\n",
    "                                                binned_map = np.zeros(grid_size)\n",
    "                                            \n",
    "                                                bin_height = height // grid_size[0]\n",
    "                                                bin_width = width // grid_size[1]\n",
    "                                            \n",
    "                                                for i in range(grid_size[0]):\n",
    "                                                    for j in range(grid_size[1]):\n",
    "                                                        bin_area = fixation_map[i*bin_height:(i+1)*bin_height, j*bin_width:(j+1)*bin_width]\n",
    "                                                        binned_map[i, j] = np.sum(bin_area)\n",
    "                                                        #ili avg?\n",
    "                                            \n",
    "                                                return binned_map\n",
    "                                            \n",
    "                                            def normalize_map(binned_map):\n",
    "                                                return binned_map / np.sum(binned_map)\n",
    "                                                #return binned_map\n",
    "                                            \n",
    "                                            def smooth_map(binned_map):\n",
    "                                                global sigma\n",
    "                                                return gaussian_filter(binned_map, sigma=sigma)\n",
    "                                            \n",
    "                                            def process_fixation_map(fixation_map):\n",
    "                                                binned_map = bin_fixations(fixation_map)\n",
    "                                                normalized_map = normalize_map(binned_map)\n",
    "                                                smoothed_map = smooth_map(normalized_map)\n",
    "                                                return smoothed_map\n",
    "                                            \n",
    "                                            def get_current_fixation_map(image_path, coordinates):\n",
    "                                                image = cv2.imread(image_path)\n",
    "                                                if image is None:\n",
    "                                                    print(f\"Image at {image_path} not found.\")\n",
    "                                                    return\n",
    "                                            \n",
    "                                                coordinates = coordinates[0:120]\n",
    "                                              \n",
    "                                                fixation_map = np.zeros((1080, 1920), dtype=np.float32)\n",
    "                                            \n",
    "                                                # Convert coordinates to pixel coordinates and update the saliency map\n",
    "                                                for x_norm, y_norm in coordinates:\n",
    "                                                    # Scale normalized coordinates to pixel coordinates for the 1920x1080 screen\n",
    "                                                    x = int(((x_norm + 1) / 2 ) * 1920)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                    y = int((y_norm + 0.5) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    # Update the saliency map if coordinates are within the screen\n",
    "                                                    if 0 <= x < 1920 and 0 <= y < 1080:\n",
    "                                                        fixation_map[y, x] += 1 \n",
    "                                            \n",
    "                                            \n",
    "                                                    '''\n",
    "                                                    # Scale normalized coordinates to pixel coordinates for the 1920x1080 screen\n",
    "                                                    if(x_norm >0 and y_norm >0):\n",
    "                                                        x = int((x_norm + 1 + 0.1) * 960)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5 + 0.05) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    if(x_norm >0 and y_norm <0):\n",
    "                                                        x = int((x_norm + 1 + 0.1) * 960)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5 - 0.1) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    if(x_norm <0 and y_norm >0):\n",
    "                                                        x = int((x_norm + 1 - 0.1) * 960)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5 + 0.05) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    if(x_norm <0 and y_norm <0):\n",
    "                                                        x = int((x_norm + 1 - 0.1) * 960)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5 - 0.1) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    # Update the saliency map if coordinates are within the screen\n",
    "                                                    if 0 <= x < 1920 and 0 <= y < 1080:\n",
    "                                                        fixation_map[y, x] += 1'''\n",
    "                                                #sigma = ppda / np.sqrt(2)\n",
    "                                                #fixation_map = gaussian_filter(fixation_map, sigma = sigma)\n",
    "                                                fixation_map = cv2.GaussianBlur(fixation_map, gaussian_size, 0)\n",
    "                                                # Crop the saliency map to the 700x700 region\n",
    "                                                fixation_map = fixation_map[190:890, 610:1310]\n",
    "                                                # flip the Y coordinates\n",
    "                                                fixation_map = np.flipud(fixation_map)\n",
    "                                                return fixation_map\n",
    "                                            \n",
    "                                            def normalize_fixation_map(fixation_map):\n",
    "                                                min_val = np.min(fixation_map)\n",
    "                                                max_val = np.max(fixation_map)\n",
    "                                                normalized_fixation_map = (fixation_map - min_val) / (max_val - min_val) * 255\n",
    "                                                return normalized_fixation_map\n",
    "                                            \n",
    "                                            # 90experiments folder\n",
    "                                            base_dir = os.path.abspath(os.path.join(os.getcwd(),\"..\", \"..\", \"90experiments\"))\n",
    "                                            \n",
    "                                            fixation_maps = {}  # Dictionary to store fixation maps for each imagePath\n",
    "                                            \n",
    "                                            \n",
    "                                            for folder in os.listdir(base_dir):\n",
    "                                                folder_path = os.path.join(base_dir, folder)\n",
    "                                                if not os.path.isdir(folder_path):\n",
    "                                                    continue\n",
    "                                                match = re.search(r'\\d{1,2}$', folder)\n",
    "                                                if match:\n",
    "                                                    observer = int(match.group())\n",
    "                                                #if(observer != 5):\n",
    "                                                #    continue\n",
    "                                                if(observer == 1 or observer == 2 or observer == 49 or observer == 50 or observer == 5):\n",
    "                                                    continue\n",
    "                                            \n",
    "                                                #if(observer not in [70,71,73,74,76,77,79,80,82,83,85,87,88,89,86,90,18,57,6,45,48,60,63,69,3,9,12,21,15,27,30,33,36,42,24,66,51,54,72,75]):\n",
    "                                                #    continue\n",
    "                                                    \n",
    "                                                csv_file_path = os.path.join(folder_path, \"eye_tracker_data.csv\")\n",
    "                                                if not os.path.isfile(csv_file_path):\n",
    "                                                    continue\n",
    "                                                data = pd.read_csv(csv_file_path)\n",
    "                                            \n",
    "                                                filtered_data = data[data['ImagePath'].str.startswith('targetImages')]\n",
    "                                                \n",
    "                                                uniqueImagePaths = []\n",
    "                                                delete_rows = []\n",
    "                                            \n",
    "                                                #get only the eye-tracking data from the first viewing\n",
    "                                                index = 0\n",
    "                                                \n",
    "                                                row = filtered_data.iloc[index]\n",
    "                                                while len(uniqueImagePaths) < 10:\n",
    "                                                    row = filtered_data.iloc[index]\n",
    "                                                    if(row['ImagePath'] not in uniqueImagePaths):\n",
    "                                                        uniqueImagePaths.append(row['ImagePath'])\n",
    "                                                        lastImagePath = row['ImagePath']\n",
    "                                                        index +=1\n",
    "                                                    elif(row['ImagePath'] in uniqueImagePaths):\n",
    "                                                        index += 1    \n",
    "                                                row = filtered_data.iloc[index]\n",
    "                                            \n",
    "                                                while(row['ImagePath'] == lastImagePath):\n",
    "                                                    index +=1\n",
    "                                                    row = filtered_data.iloc[index]\n",
    "                                            \n",
    "                                                filtered_data.reset_index(drop=True, inplace=True)\n",
    "                                                filtered_data = filtered_data.iloc[:index].copy()\n",
    "                                                \n",
    "                                                grouped = filtered_data.groupby('ImagePath')\n",
    "                                            \n",
    "                                                # Generate and save fixation maps for each image in the current folder\n",
    "                                                for image_path, group in grouped:\n",
    "                                                    # Construct full image path by going one directory back from base_dir\n",
    "                                                    full_image_path = os.path.abspath(os.path.join(base_dir, \"..\", image_path))\n",
    "                                                    full_image_path = full_image_path.replace('\\\\', '/')\n",
    "                                            \n",
    "                                                    #check if current observer has remembered this image, if not, continue\n",
    "                                                    if(not checkObserverRemembered(observer, image_path, base_dir)):\n",
    "                                                        continue\n",
    "                                                    \n",
    "                                                    # Extract coordinates\n",
    "                                                    coordinates = group[['PosX', 'PosY']].values\n",
    "                                            \n",
    "                                                    current_fixation_map = get_current_fixation_map (full_image_path, coordinates)\n",
    "                                                    if(np.all(current_fixation_map == 0)):\n",
    "                                                        continue\n",
    "                                            \n",
    "                                                    current_fixation_map_20x20 = process_fixation_map(current_fixation_map)\n",
    "                                                    current_fixation_map_20x20 = normalize_fixation_map(current_fixation_map_20x20)\n",
    "                                                    \n",
    "                                                    #current_fixation_map_20x20 = (current_fixation_map)\n",
    "                                                    #add to dictionary or update it\n",
    "                                                    if image_path not in fixation_maps:\n",
    "                                                        fixation_maps[image_path] = [current_fixation_map_20x20]\n",
    "                                                    else:\n",
    "                                                        fixation_maps[image_path].append(current_fixation_map_20x20)\n",
    "                                                        \n",
    "                                            # Flatten the fixation maps and standardize them\n",
    "                                            all_fixation_maps = []\n",
    "                                            labels = []\n",
    "                                            \n",
    "                                            for image_path, maps in fixation_maps.items():\n",
    "                                                for fixation_map in maps:\n",
    "                                                    all_fixation_maps.append(fixation_map.flatten())\n",
    "                                                    labels.append(image_path)\n",
    "                                            \n",
    "                                            X = np.array(all_fixation_maps)\n",
    "                                            y = np.array(labels)\n",
    "      \n",
    "                                            #training\n",
    "                                            from tensorflow.keras.models import Sequential\n",
    "                                            from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "                                            from tensorflow.keras.optimizers import Adam\n",
    "                                            from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "                                            from sklearn.metrics import classification_report, accuracy_score\n",
    "                                            from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "                                            from tensorflow.keras.regularizers import l2\n",
    "                                            from imblearn.over_sampling import SMOTE\n",
    "                                            import collections\n",
    "                                            import numpy as np\n",
    "                                            import matplotlib.pyplot as plt\n",
    "                                            import json\n",
    "                                            \n",
    "                                            trainings = 15\n",
    "                                            \n",
    "                                            for i in range(trainings):\n",
    "                                                X = X.reshape(-1, grid_size[0], grid_size[1], 1)\n",
    "                                            \n",
    "                                                label_encoder = LabelEncoder()\n",
    "                                                y_encoded = label_encoder.fit_transform(y)\n",
    "                                                label_names = label_encoder.classes_\n",
    "                                                \n",
    "                                                X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=test_size, stratify=y_encoded)\n",
    "                                                \n",
    "                                                y_train_categorical = to_categorical(y_train, num_classes=len(label_encoder.classes_))\n",
    "                                                y_test_categorical = to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
    "                                                \n",
    "                                                '''\n",
    "                                                # Flatten X_train for SMOTE\n",
    "                                                X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "                                                \n",
    "                                                # Apply SMOTE to balance the dataset\n",
    "                                                smote = SMOTE()\n",
    "                                                X_train_resampled, y_train_resampled = smote.fit_resample(X_train_flatten, np.argmax(y_train_categorical, axis=1))\n",
    "                                                \n",
    "                                                # Reshape X_train back to original shape\n",
    "                                                X_train_resampled = X_train_resampled.reshape(-1, grid_size[0], grid_size[1], 1)\n",
    "                                                y_train_resampled_categorical = np.eye(len(label_encoder.classes_))[y_train_resampled]\n",
    "                                                \n",
    "                                                # Calculate class weights\n",
    "                                                class_counts = collections.Counter(np.argmax(y_train_resampled_categorical, axis=1))\n",
    "                                                total_samples = sum(class_counts.values())\n",
    "                                                class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n",
    "                                                #print(\"Class counts:\", class_counts)\n",
    "                                                #print(\"Class weights:\", class_weights)\n",
    "                                                '''\n",
    "                                                # Define the MLP model\n",
    "                                                \n",
    "                                                model = Sequential([\n",
    "                                                    Input(shape=(grid_size[0], grid_size[1], 1)),\n",
    "                                                    Flatten(),\n",
    "                                                    Dense(512, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                    BatchNormalization(),\n",
    "                                                    Dropout(dropout),\n",
    "                                                    Dense(256, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                    BatchNormalization(),\n",
    "                                                    Dropout(dropout),\n",
    "                                                    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                ])\n",
    "                                                '''input_size = (32, 32)\n",
    "                                                X_train = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_train])\n",
    "                                                X_test = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_test])\n",
    "\n",
    "                                                base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "                                                model = Sequential([\n",
    "                                                    base_model,\n",
    "                                                    GlobalAveragePooling2D(),\n",
    "                                                    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "                                                    Dropout(0.5),\n",
    "                                                    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                ])'''\n",
    "                                                \n",
    "                                                # Compile the model\n",
    "                                                model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)])\n",
    "                                                \n",
    "                                                # Callbacks for learning rate adjustment and early stopping\n",
    "                                                reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, min_lr=min_lr)\n",
    "                                                early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "                                                model_checkpoint = ModelCheckpoint(os.path.join(results_folder, 'best_model_brute_force.keras'), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "                                                \n",
    "                                                \n",
    "                                                # Train the model\n",
    "                                                history = model.fit(X_train, y_train_categorical,\n",
    "                                                                    validation_data=(X_test, y_test_categorical),\n",
    "                                                                    epochs=1000,\n",
    "                                                                    callbacks=[reduce_lr, early_stopping, model_checkpoint],\n",
    "                                                                    #class_weight=class_weights,\n",
    "                                                                    batch_size = batch_size,\n",
    "                                                                    verbose = 0\n",
    "                                                                    )\n",
    "                                                \n",
    "                                                # Evaluate the model\n",
    "                                                y_pred_prob = model.predict(X_test, verbose = 0)\n",
    "                                                y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "                                                \n",
    "                                                # Calculate accuracy\n",
    "                                                accuracy = accuracy_score(y_test, y_pred)\n",
    "                                                top_3_accuracy = history.history['val_top_k_categorical_accuracy'][-1]\n",
    "                                                f1 = f1_score(y_test, y_pred, average='macro')  # You can use 'micro' or 'weighted' based on your needs\n",
    "                                                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                                                per_class_accuracy = np.mean(conf_matrix.diagonal() / conf_matrix.sum(axis=1))\n",
    "                                                balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "                                                    \n",
    "                                                if(accuracy > best_accuracy):\n",
    "                                                    best_accuracy = accuracy\n",
    "                                                    best_params = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest best accuracy: \", best_accuracy)\n",
    "                                                    print(\"Params: \", best_params)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Best accuracy: {best_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'best_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "                                                        \n",
    "                                                if(top_3_accuracy > best_top3_accuracy):\n",
    "                                                    best_top3_accuracy = top_3_accuracy\n",
    "                                                    best_params_top3 = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest top3 best accuracy: \", best_top3_accuracy)\n",
    "                                                    print(\"Params top3: \", best_params_top3)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_top3_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Top 3 accuracy: {best_top3_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best top3 parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params_top3, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'top3_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "\n",
    "                                                if(f1 > best_f1_accuracy):\n",
    "                                                    best_f1_accuracy = f1\n",
    "                                                    best_params_f1 = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest f1 best accuracy: \", best_f1_accuracy)\n",
    "                                                    print(\"Params f1: \", best_params_f1)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_f1_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Top f1 accuracy: {best_f1_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best f1 parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params_f1, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'f1_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "\n",
    "                                                if(per_class_accuracy > best_per_class_accuracy):\n",
    "                                                    best_per_class_accuracy = per_class_accuracy\n",
    "                                                    best_params_per_class = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest per class best accuracy: \", best_per_class_accuracy)\n",
    "                                                    print(\"Params per class: \", best_params_per_class)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_per_class_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Top per_class accuracy: {best_per_class_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best per class parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params_per_class, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'per_class_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "\n",
    "                                                if(balanced_accuracy > best_balanced_accuracy):\n",
    "                                                    best_balanced_accuracy = balanced_accuracy\n",
    "                                                    best_params_balanced = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest balanced best accuracy: \", best_balanced_accuracy)\n",
    "                                                    print(\"Params balanced accuracy: \", best_params_balanced)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_balanced_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Top balanced accuracy: {best_balanced_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best balanced accuracy parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params_balanced, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'balanced_accuracy_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "                                                current += 1\n",
    "                                                print(\"Current: \", current)\n",
    "                                            # Clear large data structures\n",
    "                                            del fixation_maps, all_fixation_maps, X, y\n",
    "                                            gc.collect()\n",
    "                                            \n",
    "                                            # Clear Keras session state\n",
    "                                            tf.keras.backend.clear_session()\n",
    "\n",
    "                                            # Additionally, delete the model and history to ensure they don't consume memory\n",
    "                                            del model, history, X_train, X_test, y_train, y_test, y_train_categorical, y_test_categorical, y_pred_prob, y_pred, conf_matrix\n",
    "                                            gc.collect()\n",
    "\n",
    "\n",
    "print(\"FINAL Best accuracy: \", best_accuracy)\n",
    "print(\"FINAL Params: \", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a2851b-1d87-4d42-9323-73b4b3a45130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newest best accuracy:  0.3333333333333333\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest f1 best accuracy:  0.2502380952380952\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.2944444444444444\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.2944444444444444\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  1\n",
      "Newest best accuracy:  0.3968253968253968\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest f1 best accuracy:  0.3574603174603174\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.40555555555555556\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.40555555555555556\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  2\n",
      "Newest f1 best accuracy:  0.38499999999999995\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  3\n",
      "Newest best accuracy:  0.4444444444444444\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest f1 best accuracy:  0.4164285714285715\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.45\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.45\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  4\n",
      "Current:  5\n",
      "Current:  6\n",
      "Current:  7\n",
      "Current:  8\n",
      "Newest best accuracy:  0.4603174603174603\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest f1 best accuracy:  0.44388888888888883\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.4611111111111111\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.4611111111111111\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  9\n",
      "Current:  10\n",
      "Current:  11\n",
      "Current:  12\n",
      "Current:  13\n",
      "Current:  14\n",
      "Current:  15\n",
      "Current:  16\n",
      "Current:  17\n",
      "Current:  18\n",
      "Current:  19\n",
      "Current:  20\n",
      "Current:  21\n",
      "Current:  22\n",
      "Current:  23\n",
      "Current:  24\n",
      "Current:  25\n",
      "Current:  26\n",
      "Current:  27\n",
      "Newest per class best accuracy:  0.46111111111111114\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.46111111111111114\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  28\n",
      "Newest best accuracy:  0.47619047619047616\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.4777777777777778\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.4777777777777778\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  29\n",
      "Current:  30\n",
      "Newest f1 best accuracy:  0.44555555555555554\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'randomforest'}\n",
      "Current:  31\n",
      "Current:  32\n",
      "Current:  33\n",
      "Newest best accuracy:  0.5238095238095238\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'randomforest'}\n",
      "Newest f1 best accuracy:  0.48388888888888887\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'randomforest'}\n",
      "Newest per class best accuracy:  0.5222222222222223\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'randomforest'}\n",
      "Newest balanced best accuracy:  0.5222222222222223\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'randomforest'}\n",
      "Current:  34\n",
      "Current:  35\n",
      "Current:  36\n",
      "Current:  37\n",
      "Current:  38\n",
      "Current:  39\n",
      "Newest f1 best accuracy:  0.48492063492063486\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'randomforest'}\n",
      "Current:  40\n",
      "Current:  41\n",
      "Current:  42\n",
      "Current:  43\n",
      "Current:  44\n",
      "Current:  45\n",
      "Current:  46\n",
      "Current:  47\n",
      "Current:  48\n",
      "Current:  49\n",
      "Current:  50\n",
      "Current:  51\n",
      "Current:  52\n",
      "Current:  53\n",
      "Current:  54\n",
      "Current:  55\n",
      "Current:  56\n",
      "Current:  57\n",
      "Current:  58\n",
      "Newest per class best accuracy:  0.5277777777777778\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'randomforest'}\n",
      "Newest balanced best accuracy:  0.5277777777777778\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'randomforest'}\n",
      "Current:  59\n",
      "Current:  60\n",
      "Newest top3 best accuracy:  0.6190476417541504\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  61\n",
      "Newest best accuracy:  0.5555555555555556\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest top3 best accuracy:  0.7460317611694336\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest f1 best accuracy:  0.5257142857142857\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest per class best accuracy:  0.5333333333333333\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest balanced best accuracy:  0.5333333333333333\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  62\n",
      "Current:  63\n",
      "Newest best accuracy:  0.5873015873015873\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest f1 best accuracy:  0.5555555555555555\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest per class best accuracy:  0.5777777777777777\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest balanced best accuracy:  0.5777777777777777\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  64\n",
      "Current:  65\n",
      "Current:  66\n",
      "Current:  67\n",
      "Current:  68\n",
      "Current:  69\n",
      "Current:  70\n",
      "Current:  71\n",
      "Current:  72\n",
      "Current:  73\n",
      "Current:  74\n",
      "Current:  75\n",
      "Current:  76\n",
      "Current:  77\n",
      "Current:  78\n",
      "Newest f1 best accuracy:  0.5555555555555556\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  79\n",
      "Current:  80\n",
      "Current:  81\n",
      "Current:  82\n",
      "Current:  83\n",
      "Current:  84\n",
      "Current:  85\n",
      "Newest f1 best accuracy:  0.5611111111111111\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest per class best accuracy:  0.5833333333333334\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest balanced best accuracy:  0.5833333333333334\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  86\n",
      "Current:  87\n",
      "Current:  88\n",
      "Newest best accuracy:  0.6031746031746031\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest per class best accuracy:  0.5944444444444444\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest balanced best accuracy:  0.5944444444444444\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  89\n",
      "Current:  90\n",
      "Current:  91\n",
      "Current:  92\n",
      "Current:  93\n",
      "Current:  94\n",
      "Current:  95\n",
      "Current:  96\n",
      "Current:  97\n",
      "Current:  98\n",
      "Current:  99\n",
      "Current:  100\n",
      "Current:  101\n",
      "Current:  102\n",
      "Current:  103\n",
      "Current:  104\n",
      "Current:  105\n",
      "Current:  106\n",
      "Current:  107\n",
      "Current:  108\n",
      "Current:  109\n",
      "Current:  110\n",
      "Current:  111\n",
      "Current:  112\n",
      "Current:  113\n",
      "Current:  114\n",
      "Current:  115\n",
      "Current:  116\n",
      "Current:  117\n",
      "Current:  118\n",
      "Current:  119\n",
      "Current:  120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_9880\\4159604467.py:400: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  150\n",
      "Current:  151\n",
      "Current:  152\n",
      "Current:  153\n",
      "Current:  154\n",
      "Current:  155\n",
      "Current:  156\n",
      "Current:  157\n",
      "Current:  158\n",
      "Current:  159\n",
      "Current:  160\n",
      "Current:  161\n",
      "Current:  162\n",
      "Current:  163\n",
      "Current:  164\n",
      "Current:  165\n",
      "Newest top3 best accuracy:  1.0\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'resnet'}\n",
      "Current:  166\n",
      "Current:  167\n",
      "Current:  168\n",
      "Current:  169\n",
      "Current:  170\n",
      "Current:  171\n",
      "Current:  172\n",
      "Current:  173\n",
      "Current:  174\n",
      "Current:  175\n",
      "Current:  176\n",
      "Current:  177\n",
      "Current:  178\n",
      "Current:  179\n",
      "Current:  180\n",
      "Current:  181\n",
      "Current:  182\n",
      "Current:  183\n",
      "Current:  184\n",
      "Current:  185\n",
      "Current:  186\n",
      "Current:  187\n",
      "Current:  188\n",
      "Current:  189\n",
      "Current:  190\n",
      "Current:  191\n",
      "Current:  192\n",
      "Current:  193\n",
      "Current:  194\n",
      "Newest f1 best accuracy:  0.5753968253968255\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'cnn'}\n",
      "Current:  195\n",
      "Current:  196\n",
      "Current:  197\n",
      "Current:  198\n",
      "Current:  199\n",
      "Current:  200\n",
      "Current:  201\n",
      "Current:  202\n",
      "Current:  203\n",
      "Newest per class best accuracy:  0.611111111111111\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'cnn'}\n",
      "Newest balanced best accuracy:  0.611111111111111\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'cnn'}\n",
      "Current:  204\n",
      "Current:  205\n",
      "Current:  206\n",
      "Current:  207\n",
      "Current:  208\n",
      "Current:  209\n",
      "Current:  210\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import collections\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, balanced_accuracy_score\n",
    "import gc\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "sigmas = [1]\n",
    "#grid_sizes = [(20, 20), (30, 30), (40, 40),(50, 50), (60, 60)]\n",
    "grid_sizes = [(30, 30)]\n",
    "#gaussian_sizes = [(1, 1), (19, 19), (35, 35), (43, 43)]\n",
    "gaussian_sizes = [(43, 43)]\n",
    "#batch_sizes = [32, 48, 128, 176]\n",
    "batch_sizes = [128]\n",
    "dropouts = [0.5]\n",
    "#reg_terms = [0.001, 0.0001]\n",
    "reg_terms = [0.0001]\n",
    "learning_rates = [1e-3]\n",
    "patiences = [30]\n",
    "min_lrs = [1e-6]\n",
    "factors = [0.2]\n",
    "#test_sizes = [0.1, 0.15, 0.2]\n",
    "test_sizes = [0.1]\n",
    "results_folder = \"models comparison all\"\n",
    "\n",
    "options = [\"svm\", \"randomforest\", \"mlp\", \"vgg\", \"mobilenetv2\", \"resnet\", \"cnn\"]\n",
    "#options = [\"randomforest\", \"svm\"]\n",
    "model_accuracies = {}\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "# 90experiments folder\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(),\"..\",\"..\", \"90experiments\"))\n",
    "\n",
    "best_accuracy = 0\n",
    "best_top3_accuracy = 0\n",
    "best_f1_accuracy = 0\n",
    "best_per_class_accuracy = 0\n",
    "best_balanced_accuracy = 0\n",
    "best_params = {}\n",
    "best_params_top3 = {}\n",
    "best_params_f1 = {}\n",
    "best_params_per_class = {}\n",
    "best_params_balanced_accuracy = {}\n",
    "                                            \n",
    "distance = 610\n",
    "h_res = 1920\n",
    "v_res = 1080\n",
    "screen_w = 527\n",
    "screen_h = 296\n",
    "\n",
    "current = 0\n",
    "\n",
    "                                            \n",
    "                                            \n",
    "\n",
    "def compute_ppda(distance, h_res, v_res, screen_w, screen_h):\n",
    "    \"\"\"\n",
    "    Compute the number of pixels per degree of visual angle based on the experimental conditions.\n",
    "    \n",
    "    :param distance: int, the distance between the observer and the screen (in mm)\n",
    "    :param h_res: int, the horizontal resolution of the screen\n",
    "    :param v_res: int, the vertical resolution of the screen\n",
    "    :param screen_w: int, the width of the screen (in mm)\n",
    "    :param screen_h: int, the height of the screen (in mm)\n",
    "    :return horizontal_ppda: float, the number of pixel per degree of visual angle\n",
    "    \"\"\"\n",
    "    pxl_density_x = h_res / screen_w\n",
    "    pxl_density_y = v_res / screen_h\n",
    "    \n",
    "    d = 2 * distance * math.tan(np.deg2rad(0.5))\n",
    "    horizontal_ppda = d * ((pxl_density_x + pxl_density_y) / 2)\n",
    "    \n",
    "    return horizontal_ppda\n",
    "                                            \n",
    "ppda = compute_ppda(distance, h_res, v_res, screen_w, screen_h)\n",
    "\n",
    "for option in options:\n",
    "    for test_size in test_sizes:\n",
    "        for sigma in sigmas:\n",
    "            for factor in factors:\n",
    "                for gaussian_size in gaussian_sizes:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        for dropout in dropouts:\n",
    "                            for reg_term in reg_terms:\n",
    "                                for lr in learning_rates:\n",
    "                                    for patience in patiences:\n",
    "                                        for min_lr in min_lrs:\n",
    "                                            for grid_size in grid_sizes:\n",
    "    \n",
    "                                                def checkObserverRemembered(observer, image_path, base_dir):\n",
    "                                                    csv_file_path = os.path.join(base_dir, \"..\" ,\"hit_status.csv\")\n",
    "                                                    if not os.path.isfile(csv_file_path):\n",
    "                                                        print(\"Error: CSV file not found.\")\n",
    "                                                        return False\n",
    "                                                    df = pd.read_csv(csv_file_path)\n",
    "                                                    filtered_rows = df[(df['Setup Folder'] == observer) & (df['Image Path'] == image_path) & (df['Hit'] == 1)]\n",
    "                                                    if not filtered_rows.empty:\n",
    "                                                        return True\n",
    "                                                    else:\n",
    "                                                        return False\n",
    "    \n",
    "                                                def bin_fixations(fixation_map):\n",
    "                                                    global grid_size\n",
    "                                                    height, width = fixation_map.shape\n",
    "                                                    binned_map = np.zeros(grid_size)\n",
    "                                                \n",
    "                                                    bin_height = height // grid_size[0]\n",
    "                                                    bin_width = width // grid_size[1]\n",
    "                                                \n",
    "                                                    for i in range(grid_size[0]):\n",
    "                                                        for j in range(grid_size[1]):\n",
    "                                                            bin_area = fixation_map[i*bin_height:(i+1)*bin_height, j*bin_width:(j+1)*bin_width]\n",
    "                                                            binned_map[i, j] = np.sum(bin_area)\n",
    "                                                            #ili avg?\n",
    "                                                \n",
    "                                                    return binned_map\n",
    "                                                \n",
    "                                                def normalize_map(binned_map):\n",
    "                                                    return binned_map / np.sum(binned_map)\n",
    "                                                    #return binned_map\n",
    "                                                \n",
    "                                                def smooth_map(binned_map):\n",
    "                                                    global sigma\n",
    "                                                    return gaussian_filter(binned_map, sigma=sigma)\n",
    "                                                \n",
    "                                                def process_fixation_map(fixation_map):\n",
    "                                                    binned_map = bin_fixations(fixation_map)\n",
    "                                                    normalized_map = normalize_map(binned_map)\n",
    "                                                    smoothed_map = smooth_map(normalized_map)\n",
    "                                                    return smoothed_map\n",
    "                                                \n",
    "                                                def get_current_fixation_map(image_path, coordinates):\n",
    "                                                    image = cv2.imread(image_path)\n",
    "                                                    if image is None:\n",
    "                                                        print(f\"Image at {image_path} not found.\")\n",
    "                                                        return\n",
    "                                                \n",
    "                                                    coordinates = coordinates[0:120]\n",
    "                                                  \n",
    "                                                    fixation_map = np.zeros((1080, 1920), dtype=np.float32)\n",
    "                                                \n",
    "                                                    # Convert coordinates to pixel coordinates and update the saliency map\n",
    "                                                    for x_norm, y_norm in coordinates:\n",
    "                                                        # Scale normalized coordinates to pixel coordinates for the 1920x1080 screen\n",
    "                                                        x = int(((x_norm + 1) / 2 ) * 1920)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                        # Update the saliency map if coordinates are within the screen\n",
    "                                                        if 0 <= x < 1920 and 0 <= y < 1080:\n",
    "                                                            fixation_map[y, x] += 1 \n",
    "\n",
    "                                                    fixation_map = cv2.GaussianBlur(fixation_map, gaussian_size, 0)\n",
    "                                                    # Crop the saliency map to the 700x700 region\n",
    "                                                    fixation_map = fixation_map[190:890, 610:1310]\n",
    "                                                    # flip the Y coordinates\n",
    "                                                    fixation_map = np.flipud(fixation_map)\n",
    "                                                    return fixation_map\n",
    "                                                \n",
    "                                                def normalize_fixation_map(fixation_map):\n",
    "                                                    min_val = np.min(fixation_map)\n",
    "                                                    max_val = np.max(fixation_map)\n",
    "                                                    normalized_fixation_map = (fixation_map - min_val) / (max_val - min_val) * 255\n",
    "                                                    return normalized_fixation_map\n",
    "                                                \n",
    "                                                \n",
    "                                                \n",
    "                                                fixation_maps = {}  # Dictionary to store fixation maps for each imagePath\n",
    "                                                \n",
    "                                                \n",
    "                                                for folder in os.listdir(base_dir):\n",
    "                                                    folder_path = os.path.join(base_dir, folder)\n",
    "                                                    if not os.path.isdir(folder_path):\n",
    "                                                        continue\n",
    "                                                    match = re.search(r'\\d{1,2}$', folder)\n",
    "                                                    if match:\n",
    "                                                        observer = int(match.group())\n",
    "\n",
    "                                                    if(observer == 1 or observer == 2 or observer == 49 or observer == 50 or observer == 5):\n",
    "                                                        continue\n",
    "\n",
    "                                                    csv_file_path = os.path.join(folder_path, \"eye_tracker_data.csv\")\n",
    "                                                    if not os.path.isfile(csv_file_path):\n",
    "                                                        continue\n",
    "                                                    data = pd.read_csv(csv_file_path)\n",
    "                                                \n",
    "                                                    filtered_data = data[data['ImagePath'].str.startswith('targetImages')]\n",
    "                                                    \n",
    "                                                    uniqueImagePaths = []\n",
    "                                                    delete_rows = []\n",
    "                                                \n",
    "                                                    #get only the eye-tracking data from the first viewing\n",
    "                                                    index = 0\n",
    "                                                    \n",
    "                                                    row = filtered_data.iloc[index]\n",
    "                                                    while len(uniqueImagePaths) < 10:\n",
    "                                                        row = filtered_data.iloc[index]\n",
    "                                                        if(row['ImagePath'] not in uniqueImagePaths):\n",
    "                                                            uniqueImagePaths.append(row['ImagePath'])\n",
    "                                                            lastImagePath = row['ImagePath']\n",
    "                                                            index +=1\n",
    "                                                        elif(row['ImagePath'] in uniqueImagePaths):\n",
    "                                                            index += 1    \n",
    "                                                    row = filtered_data.iloc[index]\n",
    "                                                \n",
    "                                                    while(row['ImagePath'] == lastImagePath):\n",
    "                                                        index +=1\n",
    "                                                        row = filtered_data.iloc[index]\n",
    "                                                \n",
    "                                                    filtered_data.reset_index(drop=True, inplace=True)\n",
    "                                                    filtered_data = filtered_data.iloc[:index].copy()\n",
    "                                                    \n",
    "                                                    grouped = filtered_data.groupby('ImagePath')\n",
    "                                                \n",
    "                                                    # Generate and save fixation maps for each image in the current folder\n",
    "                                                    for image_path, group in grouped:\n",
    "                                                        # Construct full image path by going one directory back from base_dir\n",
    "                                                        full_image_path = os.path.abspath(os.path.join(base_dir, \"..\", image_path))\n",
    "                                                        full_image_path = full_image_path.replace('\\\\', '/')\n",
    "                                                \n",
    "                                                        #check if current observer has remembered this image, if not, continue\n",
    "                                                        if(not checkObserverRemembered(observer, image_path, base_dir)):\n",
    "                                                            continue\n",
    "                                                        \n",
    "                                                        # Extract coordinates\n",
    "                                                        coordinates = group[['PosX', 'PosY']].values\n",
    "                                                \n",
    "                                                        current_fixation_map = get_current_fixation_map (full_image_path, coordinates)\n",
    "                                                        if(np.all(current_fixation_map == 0)):\n",
    "                                                            continue\n",
    "                                                \n",
    "                                                        current_fixation_map_20x20 = process_fixation_map(current_fixation_map)\n",
    "                                                        current_fixation_map_20x20 = normalize_fixation_map(current_fixation_map_20x20)\n",
    "                                                        \n",
    "                                                        #current_fixation_map_20x20 = (current_fixation_map)\n",
    "                                                        #add to dictionary or update it\n",
    "                                                        if image_path not in fixation_maps:\n",
    "                                                            fixation_maps[image_path] = [current_fixation_map_20x20]\n",
    "                                                        else:\n",
    "                                                            fixation_maps[image_path].append(current_fixation_map_20x20)\n",
    "                                                            \n",
    "                                                # Flatten the fixation maps and standardize them\n",
    "                                                all_fixation_maps = []\n",
    "                                                labels = []\n",
    "                                                \n",
    "                                                for image_path, maps in fixation_maps.items():\n",
    "                                                    for fixation_map in maps:\n",
    "                                                        all_fixation_maps.append(fixation_map.flatten())\n",
    "                                                        labels.append(image_path)\n",
    "                                                \n",
    "                                                X = np.array(all_fixation_maps)\n",
    "                                                y = np.array(labels)\n",
    "          \n",
    "                                                #training\n",
    "                                                from keras.applications import VGG16, MobileNetV2\n",
    "                                                from tensorflow.keras.models import Sequential\n",
    "                                                from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "                                                from tensorflow.keras.optimizers import Adam\n",
    "                                                from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "                                                from sklearn.metrics import classification_report, accuracy_score\n",
    "                                                from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "                                                from tensorflow.keras.regularizers import l2\n",
    "                                                from imblearn.over_sampling import SMOTE\n",
    "                                                import collections\n",
    "                                                import numpy as np\n",
    "                                                import matplotlib.pyplot as plt\n",
    "                                                import json\n",
    "                                                from sklearn.svm import SVC\n",
    "                                                from sklearn.ensemble import RandomForestClassifier\n",
    "                                                from sklearn.preprocessing import LabelEncoder\n",
    "                                                from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "                                                from keras.preprocessing.image import img_to_array, array_to_img\n",
    "                                                import joblib \n",
    "\n",
    "    \n",
    "                                                def save_model(model, model_save_path, option):\n",
    "                                                    # Check if the model is a Keras model by checking if it has a 'save' method\n",
    "                                                    if hasattr(model, 'save'):\n",
    "                                                        model.save(model_save_path)\n",
    "                                                    else:\n",
    "                                                        # For scikit-learn models, use joblib to save\n",
    "                                                        joblib.dump(model, model_save_path)\n",
    "                                                \n",
    "                                                trainings = 30\n",
    "                                                \n",
    "                                                for i in range(trainings):\n",
    "                                                    X = X.reshape(-1, grid_size[0], grid_size[1], 1)\n",
    "                                                \n",
    "                                                    label_encoder = LabelEncoder()\n",
    "                                                    y_encoded = label_encoder.fit_transform(y)\n",
    "                                                    label_names = label_encoder.classes_\n",
    "                                                    \n",
    "                                                    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=test_size, stratify=y_encoded)\n",
    "                                                    \n",
    "                                                    y_train_categorical = to_categorical(y_train, num_classes=len(label_encoder.classes_))\n",
    "                                                    y_test_categorical = to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "\n",
    "                                                    if(option == \"mlp\"):\n",
    "                                                        # Define the MLP model\n",
    "                                                        model = Sequential([\n",
    "                                                            Input(shape=(grid_size[0], grid_size[1], 1)),\n",
    "                                                            Flatten(),\n",
    "                                                            Dense(512, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                            BatchNormalization(),\n",
    "                                                            Dropout(dropout),\n",
    "                                                            Dense(256, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                            BatchNormalization(),\n",
    "                                                            Dropout(dropout),\n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "\n",
    "                                                    elif(option == \"cnn\"):\n",
    "                                                        # Define the CNN model\n",
    "                                                        model = Sequential([\n",
    "                                                            Input(shape=(grid_size[0], grid_size[1], 1)),\n",
    "                                                            Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                            BatchNormalization(),\n",
    "                                                            MaxPooling2D(pool_size=(2, 2)),\n",
    "                                                            Dropout(dropout),\n",
    "                                                            \n",
    "                                                            Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                            BatchNormalization(),\n",
    "                                                            MaxPooling2D(pool_size=(2, 2)),\n",
    "                                                            Dropout(dropout),\n",
    "                    \n",
    "                                                            Flatten(),\n",
    "                                                            Dense(256, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                            BatchNormalization(),\n",
    "                                                            Dropout(dropout),\n",
    "                                                            \n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "                                                    elif(option == \"resnet\"):\n",
    "                                                        \n",
    "                                                        input_size = (32, 32)\n",
    "                                                        X_train = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_train])\n",
    "                                                        X_test = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_test])\n",
    "        \n",
    "                                                        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "        \n",
    "                                                        model = Sequential([\n",
    "                                                            base_model,\n",
    "                                                            GlobalAveragePooling2D(),\n",
    "                                                            Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "                                                            Dropout(0.5),\n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "                                                    elif(option == \"vgg\"):\n",
    "                                                        # Define the input size\n",
    "                                                        input_size = (32, 32)\n",
    "                                                        \n",
    "                                                        # Convert X_train and X_test to have 3 channels and resize them\n",
    "                                                        X_train = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_train])\n",
    "                                                        X_test = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_test])\n",
    "                                                        \n",
    "                                                        # Load the VGG16 model without the top layers and specify input shape\n",
    "                                                        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "                                                        \n",
    "                                                        # Build the sequential model\n",
    "                                                        model = Sequential([\n",
    "                                                            base_model,\n",
    "                                                            GlobalAveragePooling2D(),\n",
    "                                                            Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "                                                            Dropout(0.5),\n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "\n",
    "                                                    elif(option == \"mobilenetv2\"):\n",
    "                                                        # Define the input size\n",
    "                                                        input_size = (32, 32)\n",
    "                                                        \n",
    "                                                        # Convert X_train and X_test to have 3 channels and resize them\n",
    "                                                        X_train = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_train])\n",
    "                                                        X_test = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_test])\n",
    "                                                        \n",
    "                                                        # Load the MobileNetV2 model without the top layers and specify input shape\n",
    "                                                        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "                                                        \n",
    "                                                        # Build the sequential model\n",
    "                                                        model = Sequential([\n",
    "                                                            base_model,\n",
    "                                                            GlobalAveragePooling2D(),\n",
    "                                                            Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "                                                            Dropout(0.5),\n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "                                                    elif option == \"svm\":\n",
    "                                                        input_size = (32, 32)\n",
    "                                                        X_train_flat = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)).flatten() for img in X_train])\n",
    "                                                        X_test_flat = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)).flatten() for img in X_test])\n",
    "                                                    \n",
    "                                                        label_encoder = LabelEncoder()\n",
    "                                                        y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "                                                        y_test_encoded = label_encoder.transform(y_test)\n",
    "                                                    \n",
    "                                                        model = SVC(kernel='linear', C=1.0, probability=True)\n",
    "                                                        model.fit(X_train_flat, y_train_encoded)\n",
    "                                                    \n",
    "                                                        # Predictions\n",
    "                                                        y_pred_prob = model.predict_proba(X_test_flat)\n",
    "                                                        y_pred = model.predict(X_test_flat)\n",
    "                                                    \n",
    "                                                    elif option == \"randomforest\":\n",
    "                                                        input_size = (32, 32)\n",
    "                                                        X_train_flat = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)).flatten() for img in X_train])\n",
    "                                                        X_test_flat = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)).flatten() for img in X_test])\n",
    "                                                    \n",
    "                                                        label_encoder = LabelEncoder()\n",
    "                                                        y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "                                                        y_test_encoded = label_encoder.transform(y_test)\n",
    "                                                    \n",
    "                                                        model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "                                                        model.fit(X_train_flat, y_train_encoded)\n",
    "                                                    \n",
    "                                                        # Predictions\n",
    "                                                        y_pred_prob = model.predict_proba(X_test_flat)\n",
    "                                                        y_pred = model.predict(X_test_flat)\n",
    "                                                    \n",
    "                                                    elif option == \"rusboost\":\n",
    "                                                        # Placeholder for RUSBoost implementation\n",
    "                                                        # Implement as needed for your specific case\n",
    "                                                        pass\n",
    "                                                    \n",
    "                                                    # Compile the model only for neural networks\n",
    "                                                    if option in [\"mlp\", \"resnet\", \"vgg\", \"mobilenetv2\", \"cnn\"]:\n",
    "                                                        model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy',\n",
    "                                                                      metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)])\n",
    "                                                    \n",
    "                                                        # Callbacks for learning rate adjustment and early stopping\n",
    "                                                        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, min_lr=min_lr)\n",
    "                                                        early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "                                                        model_checkpoint = ModelCheckpoint(os.path.join(results_folder, 'best_model_brute_force.keras'), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "                                                    \n",
    "                                                        # Train the model\n",
    "                                                        history = model.fit(X_train, y_train_categorical,\n",
    "                                                                            validation_data=(X_test, y_test_categorical),\n",
    "                                                                            epochs=1000,\n",
    "                                                                            callbacks=[reduce_lr, early_stopping, model_checkpoint],\n",
    "                                                                            # class_weight=class_weights,\n",
    "                                                                            batch_size=batch_size,\n",
    "                                                                            verbose=0\n",
    "                                                                            )\n",
    "                                                    \n",
    "                                                        # Evaluate the model\n",
    "                                                        y_pred_prob = model.predict(X_test, verbose=0)\n",
    "                                                        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "                                                    else:\n",
    "                                                        # For non-neural network models like SVM and RandomForest\n",
    "                                                        # We assume y_pred and y_pred_prob are already obtained above\n",
    "                                                        y_pred = model.predict(X_test_flat)\n",
    "                                                        y_pred_prob = model.predict_proba(X_test_flat)\n",
    "                                                    \n",
    "                                                    # Calculate accuracy\n",
    "                                                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                                                    if((not option in model_accuracies) or accuracy > model_accuracies[option]):\n",
    "                                                        model_accuracies[option] = accuracy\n",
    "                                                    if(option in [\"mlp\", \"resnet\", \"vgg\", \"mobilenetv2\", \"cnn\"]):\n",
    "                                                        top_3_accuracy = history.history['val_top_k_categorical_accuracy'][-1]\n",
    "                                                    else:\n",
    "                                                        top_3_accuracy = 0\n",
    "                                                    f1 = f1_score(y_test, y_pred, average='macro')  # You can use 'micro' or 'weighted' based on your needs\n",
    "                                                    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                                                    per_class_accuracy = np.mean(conf_matrix.diagonal() / conf_matrix.sum(axis=1))\n",
    "                                                    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "                                                  \n",
    "                                                        \n",
    "                                                    if(accuracy > best_accuracy):\n",
    "                                                        model_save_path = os.path.join(results_folder, 'best_model.keras')  # For Keras models\n",
    "                                                        model_save_path_sklearn = os.path.join(results_folder, 'best_model_sklearn.pkl')  # For scikit-learn models\n",
    "\n",
    "                                                        best_accuracy = accuracy\n",
    "                                                        best_params = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest best accuracy: \", best_accuracy)\n",
    "                                                        print(\"Params: \", best_params)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Best accuracy: {best_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'best_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "                                                        #save_model(model, model_save_path if option in [\"mlp\", \"resnet\", \"vgg\", \"mobilenetv2\"] else model_save_path_sklearn, option)\n",
    "\n",
    "                                                            \n",
    "                                                    if(top_3_accuracy > best_top3_accuracy):\n",
    "                                                        best_top3_accuracy = top_3_accuracy\n",
    "                                                        best_params_top3 = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest top3 best accuracy: \", best_top3_accuracy)\n",
    "                                                        print(\"Params top3: \", best_params_top3)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_top3_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Top 3 accuracy: {best_top3_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best top3 parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params_top3, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'top3_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "                                                        #save_model(model, model_save_path if option in [\"mlp\", \"resnet\", \"vgg\", \"mobilenetv2\"] else model_save_path_sklearn, option)\n",
    "\n",
    "    \n",
    "                                                    if(f1 > best_f1_accuracy):\n",
    "                                                        best_f1_accuracy = f1\n",
    "                                                        best_params_f1 = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest f1 best accuracy: \", best_f1_accuracy)\n",
    "                                                        print(\"Params f1: \", best_params_f1)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_f1_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Top f1 accuracy: {best_f1_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best f1 parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params_f1, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'f1_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "    \n",
    "                                                    if(per_class_accuracy > best_per_class_accuracy):\n",
    "                                                        best_per_class_accuracy = per_class_accuracy\n",
    "                                                        best_params_per_class = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest per class best accuracy: \", best_per_class_accuracy)\n",
    "                                                        print(\"Params per class: \", best_params_per_class)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_per_class_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Top per_class accuracy: {best_per_class_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best per class parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params_per_class, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'per_class_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "    \n",
    "                                                    if(balanced_accuracy > best_balanced_accuracy):\n",
    "                                                        best_balanced_accuracy = balanced_accuracy\n",
    "                                                        best_params_balanced = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest balanced best accuracy: \", best_balanced_accuracy)\n",
    "                                                        print(\"Params balanced accuracy: \", best_params_balanced)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_balanced_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Top balanced accuracy: {best_balanced_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best balanced accuracy parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params_balanced, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'balanced_accuracy_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "                                                    current += 1\n",
    "                                                    print(\"Current: \", current)\n",
    "                                                # Clear large data structures\n",
    "                                                del fixation_maps, all_fixation_maps, X, y\n",
    "                                                gc.collect()\n",
    "                                                \n",
    "                                                # Clear Keras session state\n",
    "                                                tf.keras.backend.clear_session()\n",
    "    \n",
    "                                                # Additionally, delete the model and history to ensure they don't consume memory\n",
    "                                                del model, X_train, X_test, y_train, y_test, y_train_categorical, y_test_categorical, y_pred_prob, y_pred, conf_matrix\n",
    "                                                gc.collect()\n",
    "\n",
    "\n",
    "#print(\"FINAL Best accuracy: \", best_accuracy)\n",
    "#print(\"FINAL Params: \", best_params)\n",
    "\n",
    "# Plotting accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_accuracies.keys(), model_accuracies.values(), color='skyblue')\n",
    "plt.xlabel('Model Option')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Each Model Option')\n",
    "plt.ylim(0, 1)  # Since accuracy is a fraction between 0 and 1\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Annotate each bar with the accuracy value\n",
    "for i, (model, acc) in enumerate(model_accuracies.items()):\n",
    "    plt.text(i, acc + 0.01, f'{acc:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('model_accuracies.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b8637-3f02-4e82-8574-dd97cda889bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
