{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e0ac92-9d90-4356-b35d-2ebf6977985b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newest best accuracy:  0.42857142857142855\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest top3 best accuracy:  0.60317462682724\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.3903174603174603\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.41111111111111115\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.41111111111111115\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  1\n",
      "Newest best accuracy:  0.5396825396825397\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest top3 best accuracy:  0.7142857313156128\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.47968253968253965\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5166666666666667\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5166666666666667\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  2\n",
      "Newest f1 best accuracy:  0.5169047619047619\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5388888888888889\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5388888888888889\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  3\n",
      "Newest best accuracy:  0.5714285714285714\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest top3 best accuracy:  0.761904776096344\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.5346825396825395\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5611111111111111\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5611111111111111\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  4\n",
      "Current:  5\n",
      "Newest best accuracy:  0.6031746031746031\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.5566666666666666\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5777777777777777\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5777777777777777\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  6\n",
      "Current:  7\n",
      "Current:  8\n",
      "Current:  9\n",
      "Current:  10\n",
      "Current:  11\n",
      "Current:  12\n",
      "Newest f1 best accuracy:  0.5647619047619048\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.5944444444444444\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.5944444444444444\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  13\n",
      "Current:  14\n",
      "Current:  15\n",
      "Current:  16\n",
      "Newest top3 best accuracy:  0.7777777910232544\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  17\n",
      "Current:  18\n",
      "Current:  19\n",
      "Current:  20\n",
      "Newest top3 best accuracy:  0.8253968358039856\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  21\n",
      "Current:  22\n",
      "Current:  23\n",
      "Current:  24\n",
      "Current:  25\n",
      "Current:  26\n",
      "Current:  27\n",
      "Current:  28\n",
      "Current:  29\n",
      "Current:  30\n",
      "Current:  31\n",
      "Current:  32\n",
      "Current:  33\n",
      "Current:  34\n",
      "Current:  35\n",
      "Current:  36\n",
      "Current:  37\n",
      "Current:  38\n",
      "Current:  39\n",
      "Current:  40\n",
      "Current:  41\n",
      "Current:  42\n",
      "Current:  43\n",
      "Current:  44\n",
      "Current:  45\n",
      "Current:  46\n",
      "Current:  47\n",
      "Current:  48\n",
      "Current:  49\n",
      "Current:  50\n",
      "Newest best accuracy:  0.6507936507936508\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest f1 best accuracy:  0.6072222222222223\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest per class best accuracy:  0.65\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Newest balanced best accuracy:  0.65\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  51\n",
      "Current:  52\n",
      "Current:  53\n",
      "Current:  54\n",
      "Current:  55\n",
      "Current:  56\n",
      "Current:  57\n",
      "Current:  58\n",
      "Current:  59\n",
      "Current:  60\n",
      "Current:  61\n",
      "Current:  62\n",
      "Newest f1 best accuracy:  0.61\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n",
      "Current:  63\n",
      "Current:  64\n",
      "Current:  65\n",
      "Current:  66\n",
      "Current:  67\n",
      "Current:  68\n",
      "Current:  69\n",
      "Current:  70\n",
      "Current:  71\n",
      "Current:  72\n",
      "Current:  73\n",
      "Current:  74\n",
      "Current:  75\n",
      "Current:  76\n",
      "Current:  77\n",
      "Current:  78\n",
      "Current:  79\n",
      "Current:  80\n",
      "Current:  81\n",
      "Current:  82\n",
      "Current:  83\n",
      "Current:  84\n",
      "Current:  85\n",
      "Current:  86\n",
      "Current:  87\n",
      "Current:  88\n",
      "Current:  89\n",
      "Current:  90\n",
      "Current:  91\n",
      "Current:  92\n",
      "Current:  93\n",
      "Current:  94\n",
      "Current:  95\n",
      "Current:  96\n",
      "Current:  97\n",
      "Current:  98\n",
      "Current:  99\n",
      "Current:  100\n",
      "Current:  101\n",
      "Current:  102\n",
      "Current:  103\n",
      "Current:  104\n",
      "Current:  105\n",
      "Current:  106\n",
      "Current:  107\n",
      "Current:  108\n",
      "Current:  109\n",
      "Current:  110\n",
      "Current:  111\n",
      "Current:  112\n",
      "Current:  113\n",
      "Current:  114\n",
      "Current:  115\n",
      "Current:  116\n",
      "Current:  117\n",
      "Current:  118\n",
      "Current:  119\n",
      "Current:  120\n",
      "Current:  121\n",
      "Current:  122\n",
      "Current:  123\n",
      "Current:  124\n",
      "Current:  125\n",
      "Current:  126\n",
      "Current:  127\n",
      "Current:  128\n",
      "Current:  129\n",
      "Current:  130\n",
      "Current:  131\n",
      "Current:  132\n",
      "Current:  133\n",
      "Current:  134\n",
      "Current:  135\n",
      "Current:  136\n",
      "Current:  137\n",
      "Current:  138\n",
      "Current:  139\n",
      "Current:  140\n",
      "Current:  141\n",
      "Current:  142\n",
      "Current:  143\n",
      "Current:  144\n",
      "Current:  145\n",
      "Current:  146\n",
      "Current:  147\n",
      "Current:  148\n",
      "Current:  149\n",
      "Current:  150\n",
      "FINAL Best accuracy:  0.6507936507936508\n",
      "FINAL Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import collections\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, balanced_accuracy_score\n",
    "import gc\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "sigmas = [1]\n",
    "#grid_sizes = [(20, 20), (30, 30), (40, 40),(50, 50), (60, 60)]\n",
    "grid_sizes = [(30, 30)]\n",
    "#gaussian_sizes = [(1, 1), (19, 19), (35, 35), (43, 43)]\n",
    "gaussian_sizes = [(43, 43)]\n",
    "#batch_sizes = [32, 48, 128, 176]\n",
    "batch_sizes = [128]\n",
    "dropouts = [0.5]\n",
    "#reg_terms = [0.001, 0.0001]\n",
    "reg_terms = [0.0001]\n",
    "learning_rates = [1e-3]\n",
    "patiences = [30]\n",
    "min_lrs = [1e-6]\n",
    "factors = [0.2]\n",
    "#test_sizes = [0.1, 0.15, 0.2]\n",
    "test_sizes = [0.1]\n",
    "results_folder = \"MODELS COMPARISON\"\n",
    "\n",
    "options =\n",
    "\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_top3_accuracy = 0\n",
    "best_f1_accuracy = 0\n",
    "best_per_class_accuracy = 0\n",
    "best_balanced_accuracy = 0\n",
    "best_params = {}\n",
    "best_params_top3 = {}\n",
    "best_params_f1 = {}\n",
    "best_params_per_class = {}\n",
    "best_params_balanced_accuracy = {}\n",
    "                                            \n",
    "distance = 610\n",
    "h_res = 1920\n",
    "v_res = 1080\n",
    "screen_w = 527\n",
    "screen_h = 296\n",
    "\n",
    "current = 0\n",
    "\n",
    "                                            \n",
    "                                            \n",
    "\n",
    "def compute_ppda(distance, h_res, v_res, screen_w, screen_h):\n",
    "    \"\"\"\n",
    "    Compute the number of pixels per degree of visual angle based on the experimental conditions.\n",
    "    \n",
    "    :param distance: int, the distance between the observer and the screen (in mm)\n",
    "    :param h_res: int, the horizontal resolution of the screen\n",
    "    :param v_res: int, the vertical resolution of the screen\n",
    "    :param screen_w: int, the width of the screen (in mm)\n",
    "    :param screen_h: int, the height of the screen (in mm)\n",
    "    :return horizontal_ppda: float, the number of pixel per degree of visual angle\n",
    "    \"\"\"\n",
    "    pxl_density_x = h_res / screen_w\n",
    "    pxl_density_y = v_res / screen_h\n",
    "    \n",
    "    d = 2 * distance * math.tan(np.deg2rad(0.5))\n",
    "    horizontal_ppda = d * ((pxl_density_x + pxl_density_y) / 2)\n",
    "    \n",
    "    return horizontal_ppda\n",
    "                                            \n",
    "ppda = compute_ppda(distance, h_res, v_res, screen_w, screen_h)\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    for sigma in sigmas:\n",
    "        for factor in factors:\n",
    "            for gaussian_size in gaussian_sizes:\n",
    "                for batch_size in batch_sizes:\n",
    "                    for dropout in dropouts:\n",
    "                        for reg_term in reg_terms:\n",
    "                            for lr in learning_rates:\n",
    "                                for patience in patiences:\n",
    "                                    for min_lr in min_lrs:\n",
    "                                        for grid_size in grid_sizes:\n",
    "\n",
    "                                            def checkObserverRemembered(observer, image_path, base_dir):\n",
    "                                                csv_file_path = os.path.join(base_dir, \"..\" ,\"hit_status.csv\")\n",
    "                                                if not os.path.isfile(csv_file_path):\n",
    "                                                    print(\"Error: CSV file not found.\")\n",
    "                                                    return False\n",
    "                                                df = pd.read_csv(csv_file_path)\n",
    "                                                filtered_rows = df[(df['Setup Folder'] == observer) & (df['Image Path'] == image_path) & (df['Hit'] == 1)]\n",
    "                                                if not filtered_rows.empty:\n",
    "                                                    return True\n",
    "                                                else:\n",
    "                                                    return False\n",
    "\n",
    "                                            def bin_fixations(fixation_map):\n",
    "                                                global grid_size\n",
    "                                                height, width = fixation_map.shape\n",
    "                                                binned_map = np.zeros(grid_size)\n",
    "                                            \n",
    "                                                bin_height = height // grid_size[0]\n",
    "                                                bin_width = width // grid_size[1]\n",
    "                                            \n",
    "                                                for i in range(grid_size[0]):\n",
    "                                                    for j in range(grid_size[1]):\n",
    "                                                        bin_area = fixation_map[i*bin_height:(i+1)*bin_height, j*bin_width:(j+1)*bin_width]\n",
    "                                                        binned_map[i, j] = np.sum(bin_area)\n",
    "                                                        #ili avg?\n",
    "                                            \n",
    "                                                return binned_map\n",
    "                                            \n",
    "                                            def normalize_map(binned_map):\n",
    "                                                return binned_map / np.sum(binned_map)\n",
    "                                                #return binned_map\n",
    "                                            \n",
    "                                            def smooth_map(binned_map):\n",
    "                                                global sigma\n",
    "                                                return gaussian_filter(binned_map, sigma=sigma)\n",
    "                                            \n",
    "                                            def process_fixation_map(fixation_map):\n",
    "                                                binned_map = bin_fixations(fixation_map)\n",
    "                                                normalized_map = normalize_map(binned_map)\n",
    "                                                smoothed_map = smooth_map(normalized_map)\n",
    "                                                return smoothed_map\n",
    "                                            \n",
    "                                            def get_current_fixation_map(image_path, coordinates):\n",
    "                                                image = cv2.imread(image_path)\n",
    "                                                if image is None:\n",
    "                                                    print(f\"Image at {image_path} not found.\")\n",
    "                                                    return\n",
    "                                            \n",
    "                                                coordinates = coordinates[0:120]\n",
    "                                              \n",
    "                                                fixation_map = np.zeros((1080, 1920), dtype=np.float32)\n",
    "                                            \n",
    "                                                # Convert coordinates to pixel coordinates and update the saliency map\n",
    "                                                for x_norm, y_norm in coordinates:\n",
    "                                                    # Scale normalized coordinates to pixel coordinates for the 1920x1080 screen\n",
    "                                                    x = int(((x_norm + 1) / 2 ) * 1920)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                    y = int((y_norm + 0.5) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    # Update the saliency map if coordinates are within the screen\n",
    "                                                    if 0 <= x < 1920 and 0 <= y < 1080:\n",
    "                                                        fixation_map[y, x] += 1 \n",
    "                                            \n",
    "                                            \n",
    "                                                    '''\n",
    "                                                    # Scale normalized coordinates to pixel coordinates for the 1920x1080 screen\n",
    "                                                    if(x_norm >0 and y_norm >0):\n",
    "                                                        x = int((x_norm + 1 + 0.1) * 960)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5 + 0.05) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    if(x_norm >0 and y_norm <0):\n",
    "                                                        x = int((x_norm + 1 + 0.1) * 960)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5 - 0.1) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    if(x_norm <0 and y_norm >0):\n",
    "                                                        x = int((x_norm + 1 - 0.1) * 960)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5 + 0.05) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    if(x_norm <0 and y_norm <0):\n",
    "                                                        x = int((x_norm + 1 - 0.1) * 960)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5 - 0.1) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                    # Update the saliency map if coordinates are within the screen\n",
    "                                                    if 0 <= x < 1920 and 0 <= y < 1080:\n",
    "                                                        fixation_map[y, x] += 1'''\n",
    "                                                #sigma = ppda / np.sqrt(2)\n",
    "                                                #fixation_map = gaussian_filter(fixation_map, sigma = sigma)\n",
    "                                                fixation_map = cv2.GaussianBlur(fixation_map, gaussian_size, 0)\n",
    "                                                # Crop the saliency map to the 700x700 region\n",
    "                                                fixation_map = fixation_map[190:890, 610:1310]\n",
    "                                                # flip the Y coordinates\n",
    "                                                fixation_map = np.flipud(fixation_map)\n",
    "                                                return fixation_map\n",
    "                                            \n",
    "                                            def normalize_fixation_map(fixation_map):\n",
    "                                                min_val = np.min(fixation_map)\n",
    "                                                max_val = np.max(fixation_map)\n",
    "                                                normalized_fixation_map = (fixation_map - min_val) / (max_val - min_val) * 255\n",
    "                                                return normalized_fixation_map\n",
    "                                            \n",
    "                                            # 90experiments folder\n",
    "                                            base_dir = os.path.abspath(os.path.join(os.getcwd(),\"..\", \"..\", \"90experiments\"))\n",
    "                                            \n",
    "                                            fixation_maps = {}  # Dictionary to store fixation maps for each imagePath\n",
    "                                            \n",
    "                                            \n",
    "                                            for folder in os.listdir(base_dir):\n",
    "                                                folder_path = os.path.join(base_dir, folder)\n",
    "                                                if not os.path.isdir(folder_path):\n",
    "                                                    continue\n",
    "                                                match = re.search(r'\\d{1,2}$', folder)\n",
    "                                                if match:\n",
    "                                                    observer = int(match.group())\n",
    "                                                #if(observer != 5):\n",
    "                                                #    continue\n",
    "                                                if(observer == 1 or observer == 2 or observer == 49 or observer == 50 or observer == 5):\n",
    "                                                    continue\n",
    "                                            \n",
    "                                                #if(observer not in [70,71,73,74,76,77,79,80,82,83,85,87,88,89,86,90,18,57,6,45,48,60,63,69,3,9,12,21,15,27,30,33,36,42,24,66,51,54,72,75]):\n",
    "                                                #    continue\n",
    "                                                    \n",
    "                                                csv_file_path = os.path.join(folder_path, \"eye_tracker_data.csv\")\n",
    "                                                if not os.path.isfile(csv_file_path):\n",
    "                                                    continue\n",
    "                                                data = pd.read_csv(csv_file_path)\n",
    "                                            \n",
    "                                                filtered_data = data[data['ImagePath'].str.startswith('targetImages')]\n",
    "                                                \n",
    "                                                uniqueImagePaths = []\n",
    "                                                delete_rows = []\n",
    "                                            \n",
    "                                                #get only the eye-tracking data from the first viewing\n",
    "                                                index = 0\n",
    "                                                \n",
    "                                                row = filtered_data.iloc[index]\n",
    "                                                while len(uniqueImagePaths) < 10:\n",
    "                                                    row = filtered_data.iloc[index]\n",
    "                                                    if(row['ImagePath'] not in uniqueImagePaths):\n",
    "                                                        uniqueImagePaths.append(row['ImagePath'])\n",
    "                                                        lastImagePath = row['ImagePath']\n",
    "                                                        index +=1\n",
    "                                                    elif(row['ImagePath'] in uniqueImagePaths):\n",
    "                                                        index += 1    \n",
    "                                                row = filtered_data.iloc[index]\n",
    "                                            \n",
    "                                                while(row['ImagePath'] == lastImagePath):\n",
    "                                                    index +=1\n",
    "                                                    row = filtered_data.iloc[index]\n",
    "                                            \n",
    "                                                filtered_data.reset_index(drop=True, inplace=True)\n",
    "                                                filtered_data = filtered_data.iloc[:index].copy()\n",
    "                                                \n",
    "                                                grouped = filtered_data.groupby('ImagePath')\n",
    "                                            \n",
    "                                                # Generate and save fixation maps for each image in the current folder\n",
    "                                                for image_path, group in grouped:\n",
    "                                                    # Construct full image path by going one directory back from base_dir\n",
    "                                                    full_image_path = os.path.abspath(os.path.join(base_dir, \"..\", image_path))\n",
    "                                                    full_image_path = full_image_path.replace('\\\\', '/')\n",
    "                                            \n",
    "                                                    #check if current observer has remembered this image, if not, continue\n",
    "                                                    if(not checkObserverRemembered(observer, image_path, base_dir)):\n",
    "                                                        continue\n",
    "                                                    \n",
    "                                                    # Extract coordinates\n",
    "                                                    coordinates = group[['PosX', 'PosY']].values\n",
    "                                            \n",
    "                                                    current_fixation_map = get_current_fixation_map (full_image_path, coordinates)\n",
    "                                                    if(np.all(current_fixation_map == 0)):\n",
    "                                                        continue\n",
    "                                            \n",
    "                                                    current_fixation_map_20x20 = process_fixation_map(current_fixation_map)\n",
    "                                                    current_fixation_map_20x20 = normalize_fixation_map(current_fixation_map_20x20)\n",
    "                                                    \n",
    "                                                    #current_fixation_map_20x20 = (current_fixation_map)\n",
    "                                                    #add to dictionary or update it\n",
    "                                                    if image_path not in fixation_maps:\n",
    "                                                        fixation_maps[image_path] = [current_fixation_map_20x20]\n",
    "                                                    else:\n",
    "                                                        fixation_maps[image_path].append(current_fixation_map_20x20)\n",
    "                                                        \n",
    "                                            # Flatten the fixation maps and standardize them\n",
    "                                            all_fixation_maps = []\n",
    "                                            labels = []\n",
    "                                            \n",
    "                                            for image_path, maps in fixation_maps.items():\n",
    "                                                for fixation_map in maps:\n",
    "                                                    all_fixation_maps.append(fixation_map.flatten())\n",
    "                                                    labels.append(image_path)\n",
    "                                            \n",
    "                                            X = np.array(all_fixation_maps)\n",
    "                                            y = np.array(labels)\n",
    "      \n",
    "                                            #training\n",
    "                                            from tensorflow.keras.models import Sequential\n",
    "                                            from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "                                            from tensorflow.keras.optimizers import Adam\n",
    "                                            from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "                                            from sklearn.metrics import classification_report, accuracy_score\n",
    "                                            from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "                                            from tensorflow.keras.regularizers import l2\n",
    "                                            from imblearn.over_sampling import SMOTE\n",
    "                                            import collections\n",
    "                                            import numpy as np\n",
    "                                            import matplotlib.pyplot as plt\n",
    "                                            import json\n",
    "                                            \n",
    "                                            trainings = 15\n",
    "                                            \n",
    "                                            for i in range(trainings):\n",
    "                                                X = X.reshape(-1, grid_size[0], grid_size[1], 1)\n",
    "                                            \n",
    "                                                label_encoder = LabelEncoder()\n",
    "                                                y_encoded = label_encoder.fit_transform(y)\n",
    "                                                label_names = label_encoder.classes_\n",
    "                                                \n",
    "                                                X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=test_size, stratify=y_encoded)\n",
    "                                                \n",
    "                                                y_train_categorical = to_categorical(y_train, num_classes=len(label_encoder.classes_))\n",
    "                                                y_test_categorical = to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
    "                                                \n",
    "                                                '''\n",
    "                                                # Flatten X_train for SMOTE\n",
    "                                                X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "                                                \n",
    "                                                # Apply SMOTE to balance the dataset\n",
    "                                                smote = SMOTE()\n",
    "                                                X_train_resampled, y_train_resampled = smote.fit_resample(X_train_flatten, np.argmax(y_train_categorical, axis=1))\n",
    "                                                \n",
    "                                                # Reshape X_train back to original shape\n",
    "                                                X_train_resampled = X_train_resampled.reshape(-1, grid_size[0], grid_size[1], 1)\n",
    "                                                y_train_resampled_categorical = np.eye(len(label_encoder.classes_))[y_train_resampled]\n",
    "                                                \n",
    "                                                # Calculate class weights\n",
    "                                                class_counts = collections.Counter(np.argmax(y_train_resampled_categorical, axis=1))\n",
    "                                                total_samples = sum(class_counts.values())\n",
    "                                                class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n",
    "                                                #print(\"Class counts:\", class_counts)\n",
    "                                                #print(\"Class weights:\", class_weights)\n",
    "                                                '''\n",
    "                                                # Define the MLP model\n",
    "                                                \n",
    "                                                model = Sequential([\n",
    "                                                    Input(shape=(grid_size[0], grid_size[1], 1)),\n",
    "                                                    Flatten(),\n",
    "                                                    Dense(512, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                    BatchNormalization(),\n",
    "                                                    Dropout(dropout),\n",
    "                                                    Dense(256, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                    BatchNormalization(),\n",
    "                                                    Dropout(dropout),\n",
    "                                                    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                ])\n",
    "                                                '''input_size = (32, 32)\n",
    "                                                X_train = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_train])\n",
    "                                                X_test = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_test])\n",
    "\n",
    "                                                base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "                                                model = Sequential([\n",
    "                                                    base_model,\n",
    "                                                    GlobalAveragePooling2D(),\n",
    "                                                    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "                                                    Dropout(0.5),\n",
    "                                                    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                ])'''\n",
    "                                                \n",
    "                                                # Compile the model\n",
    "                                                model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)])\n",
    "                                                \n",
    "                                                # Callbacks for learning rate adjustment and early stopping\n",
    "                                                reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, min_lr=min_lr)\n",
    "                                                early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "                                                model_checkpoint = ModelCheckpoint(os.path.join(results_folder, 'best_model_brute_force.keras'), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "                                                \n",
    "                                                \n",
    "                                                # Train the model\n",
    "                                                history = model.fit(X_train, y_train_categorical,\n",
    "                                                                    validation_data=(X_test, y_test_categorical),\n",
    "                                                                    epochs=1000,\n",
    "                                                                    callbacks=[reduce_lr, early_stopping, model_checkpoint],\n",
    "                                                                    #class_weight=class_weights,\n",
    "                                                                    batch_size = batch_size,\n",
    "                                                                    verbose = 0\n",
    "                                                                    )\n",
    "                                                \n",
    "                                                # Evaluate the model\n",
    "                                                y_pred_prob = model.predict(X_test, verbose = 0)\n",
    "                                                y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "                                                \n",
    "                                                # Calculate accuracy\n",
    "                                                accuracy = accuracy_score(y_test, y_pred)\n",
    "                                                top_3_accuracy = history.history['val_top_k_categorical_accuracy'][-1]\n",
    "                                                f1 = f1_score(y_test, y_pred, average='macro')  # You can use 'micro' or 'weighted' based on your needs\n",
    "                                                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                                                per_class_accuracy = np.mean(conf_matrix.diagonal() / conf_matrix.sum(axis=1))\n",
    "                                                balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "                                                    \n",
    "                                                if(accuracy > best_accuracy):\n",
    "                                                    best_accuracy = accuracy\n",
    "                                                    best_params = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest best accuracy: \", best_accuracy)\n",
    "                                                    print(\"Params: \", best_params)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Best accuracy: {best_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'best_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "                                                        \n",
    "                                                if(top_3_accuracy > best_top3_accuracy):\n",
    "                                                    best_top3_accuracy = top_3_accuracy\n",
    "                                                    best_params_top3 = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest top3 best accuracy: \", best_top3_accuracy)\n",
    "                                                    print(\"Params top3: \", best_params_top3)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_top3_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Top 3 accuracy: {best_top3_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best top3 parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params_top3, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'top3_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "\n",
    "                                                if(f1 > best_f1_accuracy):\n",
    "                                                    best_f1_accuracy = f1\n",
    "                                                    best_params_f1 = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest f1 best accuracy: \", best_f1_accuracy)\n",
    "                                                    print(\"Params f1: \", best_params_f1)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_f1_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Top f1 accuracy: {best_f1_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best f1 parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params_f1, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'f1_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "\n",
    "                                                if(per_class_accuracy > best_per_class_accuracy):\n",
    "                                                    best_per_class_accuracy = per_class_accuracy\n",
    "                                                    best_params_per_class = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest per class best accuracy: \", best_per_class_accuracy)\n",
    "                                                    print(\"Params per class: \", best_params_per_class)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_per_class_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Top per_class accuracy: {best_per_class_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best per class parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params_per_class, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'per_class_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "\n",
    "                                                if(balanced_accuracy > best_balanced_accuracy):\n",
    "                                                    best_balanced_accuracy = balanced_accuracy\n",
    "                                                    best_params_balanced = {\n",
    "                                                                   'sigma':sigma, \n",
    "                                                                   'grid_size':grid_size, \n",
    "                                                                   'gaussian_size':gaussian_size,\n",
    "                                                                   'batch_size':batch_size,\n",
    "                                                                   'dropout':dropout,\n",
    "                                                                   'reg_term':reg_term,\n",
    "                                                                   'lr':lr,\n",
    "                                                                   'patience':patience,\n",
    "                                                                   'min_lr':min_lr,\n",
    "                                                                   'factor':factor,\n",
    "                                                                   'test_size': test_size}\n",
    "                                                    print(\"Newest balanced best accuracy: \", best_balanced_accuracy)\n",
    "                                                    print(\"Params balanced accuracy: \", best_params_balanced)\n",
    "                                                    # Save the best model, accuracy and top-3 accuracy\n",
    "                                                    with open(os.path.join(results_folder, \"best_accuracy_MLP_search_balanced_accuracy.txt\"), \"w\") as f:\n",
    "                                                        f.write(f\"Top balanced accuracy: {best_balanced_accuracy:.4f}\\n\")\n",
    "                                                        f.write(\"Best balanced accuracy parameters:\\n\")\n",
    "                                                        f.write(json.dumps(best_params_balanced, indent=4))\n",
    "                                                    # Define the path to save the model\n",
    "                                                    model_save_path = os.path.join(results_folder, 'balanced_accuracy_model.keras')\n",
    "                                                    # Save the model\n",
    "                                                    model.save(model_save_path)\n",
    "                                                current += 1\n",
    "                                                print(\"Current: \", current)\n",
    "                                            # Clear large data structures\n",
    "                                            del fixation_maps, all_fixation_maps, X, y\n",
    "                                            gc.collect()\n",
    "                                            \n",
    "                                            # Clear Keras session state\n",
    "                                            tf.keras.backend.clear_session()\n",
    "\n",
    "                                            # Additionally, delete the model and history to ensure they don't consume memory\n",
    "                                            del model, history, X_train, X_test, y_train, y_test, y_train_categorical, y_test_categorical, y_pred_prob, y_pred, conf_matrix\n",
    "                                            gc.collect()\n",
    "\n",
    "\n",
    "print(\"FINAL Best accuracy: \", best_accuracy)\n",
    "print(\"FINAL Params: \", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a2851b-1d87-4d42-9323-73b4b3a45130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newest best accuracy:  0.3968253968253968\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest f1 best accuracy:  0.3495238095238095\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.3888888888888889\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.3888888888888889\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  1\n",
      "Newest best accuracy:  0.4444444444444444\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest f1 best accuracy:  0.4128571428571428\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.44999999999999996\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.44999999999999996\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  2\n",
      "Current:  3\n",
      "Current:  4\n",
      "Current:  5\n",
      "Current:  6\n",
      "Current:  7\n",
      "Current:  8\n",
      "Current:  9\n",
      "Current:  10\n",
      "Current:  11\n",
      "Current:  12\n",
      "Current:  13\n",
      "Current:  14\n",
      "Current:  15\n",
      "Current:  16\n",
      "Current:  17\n",
      "Newest f1 best accuracy:  0.42571428571428566\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  18\n",
      "Current:  19\n",
      "Newest best accuracy:  0.5079365079365079\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest f1 best accuracy:  0.47587301587301595\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.5\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.5\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  20\n",
      "Current:  21\n",
      "Newest best accuracy:  0.5396825396825397\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest f1 best accuracy:  0.5055555555555555\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest per class best accuracy:  0.5444444444444444\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Newest balanced best accuracy:  0.5444444444444444\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'svm'}\n",
      "Current:  22\n",
      "Current:  23\n",
      "Current:  24\n",
      "Current:  25\n",
      "Current:  26\n",
      "Current:  27\n",
      "Current:  28\n",
      "Current:  29\n",
      "Current:  30\n",
      "WARNING:tensorflow:From C:\\Users\\valerijan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Current:  31\n",
      "Current:  32\n",
      "Current:  33\n",
      "Current:  34\n",
      "Current:  35\n",
      "Current:  36\n",
      "Current:  37\n",
      "Current:  38\n",
      "Current:  39\n",
      "Current:  40\n",
      "Current:  41\n",
      "Current:  42\n",
      "Current:  43\n",
      "Current:  44\n",
      "Current:  45\n",
      "Current:  46\n",
      "Current:  47\n",
      "Current:  48\n",
      "Current:  49\n",
      "Current:  50\n",
      "Current:  51\n",
      "Current:  52\n",
      "Current:  53\n",
      "Current:  54\n",
      "Current:  55\n",
      "Current:  56\n",
      "Current:  57\n",
      "Current:  58\n",
      "Current:  59\n",
      "Current:  60\n",
      "Newest top3 best accuracy:  0.6349206566810608\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest f1 best accuracy:  0.5062698412698413\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  61\n",
      "Newest top3 best accuracy:  0.7777777910232544\n",
      "Params top3:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  62\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020AEAECE3E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020AEAECE3E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Current:  63\n",
      "Current:  64\n",
      "Current:  65\n",
      "Newest best accuracy:  0.5555555555555556\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest f1 best accuracy:  0.5161111111111112\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest per class best accuracy:  0.55\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest balanced best accuracy:  0.55\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  66\n",
      "Newest best accuracy:  0.5873015873015873\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest f1 best accuracy:  0.5281746031746032\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest per class best accuracy:  0.5833333333333334\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest balanced best accuracy:  0.5833333333333334\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  67\n",
      "Current:  68\n",
      "Newest f1 best accuracy:  0.5611111111111111\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  69\n",
      "Current:  70\n",
      "Current:  71\n",
      "Current:  72\n",
      "Current:  73\n",
      "Current:  74\n",
      "Current:  75\n",
      "Current:  76\n",
      "Current:  77\n",
      "Current:  78\n",
      "Current:  79\n",
      "Current:  80\n",
      "Current:  81\n",
      "Current:  82\n",
      "Newest best accuracy:  0.6031746031746031\n",
      "Params:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest f1 best accuracy:  0.5855555555555555\n",
      "Params f1:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest per class best accuracy:  0.6222222222222222\n",
      "Params per class:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Newest balanced best accuracy:  0.6222222222222222\n",
      "Params balanced accuracy:  {'sigma': 1, 'grid_size': (30, 30), 'gaussian_size': (43, 43), 'batch_size': 128, 'dropout': 0.5, 'reg_term': 0.0001, 'lr': 0.001, 'patience': 30, 'min_lr': 1e-06, 'factor': 0.2, 'test_size': 0.1, 'model': 'mlp'}\n",
      "Current:  83\n",
      "Current:  84\n",
      "Current:  85\n",
      "Current:  86\n",
      "Current:  87\n",
      "Current:  88\n",
      "Current:  89\n",
      "Current:  90\n",
      "Current:  91\n",
      "Current:  92\n",
      "Current:  93\n",
      "Current:  94\n",
      "Current:  95\n",
      "Current:  96\n",
      "Current:  97\n",
      "Current:  98\n",
      "Current:  99\n",
      "Current:  100\n",
      "Current:  101\n",
      "Current:  102\n",
      "Current:  103\n",
      "Current:  104\n",
      "Current:  105\n",
      "Current:  106\n",
      "Current:  107\n",
      "Current:  108\n",
      "Current:  109\n",
      "Current:  110\n",
      "Current:  111\n",
      "Current:  112\n",
      "Current:  113\n",
      "Current:  114\n",
      "Current:  115\n",
      "Current:  116\n",
      "Current:  117\n",
      "Current:  118\n",
      "Current:  119\n",
      "Current:  120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valerijan\\AppData\\Local\\Temp\\ipykernel_10912\\535144714.py:376: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current:  150\n",
      "Current:  151\n",
      "Current:  152\n",
      "Current:  153\n",
      "Current:  154\n",
      "Current:  155\n",
      "Current:  156\n",
      "Current:  157\n",
      "Current:  158\n",
      "Current:  159\n",
      "Current:  160\n",
      "Current:  161\n",
      "Current:  162\n",
      "Current:  163\n",
      "Current:  164\n",
      "Current:  165\n",
      "Current:  166\n",
      "Current:  167\n",
      "Current:  168\n",
      "Current:  169\n",
      "Current:  170\n",
      "Current:  171\n",
      "Current:  172\n",
      "Current:  173\n",
      "Current:  174\n",
      "Current:  175\n",
      "Current:  176\n",
      "Current:  177\n",
      "Current:  178\n",
      "Current:  179\n",
      "Current:  180\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import collections\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, balanced_accuracy_score\n",
    "import gc\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "sigmas = [1]\n",
    "#grid_sizes = [(20, 20), (30, 30), (40, 40),(50, 50), (60, 60)]\n",
    "grid_sizes = [(30, 30)]\n",
    "#gaussian_sizes = [(1, 1), (19, 19), (35, 35), (43, 43)]\n",
    "gaussian_sizes = [(43, 43)]\n",
    "#batch_sizes = [32, 48, 128, 176]\n",
    "batch_sizes = [128]\n",
    "dropouts = [0.5]\n",
    "#reg_terms = [0.001, 0.0001]\n",
    "reg_terms = [0.0001]\n",
    "learning_rates = [1e-3]\n",
    "patiences = [30]\n",
    "min_lrs = [1e-6]\n",
    "factors = [0.2]\n",
    "#test_sizes = [0.1, 0.15, 0.2]\n",
    "test_sizes = [0.1]\n",
    "results_folder = \"models comparison all\"\n",
    "\n",
    "options = [\"svm\", \"randomforest\", \"mlp\", \"vgg\", \"mobilenetv2\", \"resnet\"]\n",
    "#options = [\"randomforest\", \"svm\"]\n",
    "model_accuracies = {}\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "best_accuracy = 0\n",
    "best_top3_accuracy = 0\n",
    "best_f1_accuracy = 0\n",
    "best_per_class_accuracy = 0\n",
    "best_balanced_accuracy = 0\n",
    "best_params = {}\n",
    "best_params_top3 = {}\n",
    "best_params_f1 = {}\n",
    "best_params_per_class = {}\n",
    "best_params_balanced_accuracy = {}\n",
    "                                            \n",
    "distance = 610\n",
    "h_res = 1920\n",
    "v_res = 1080\n",
    "screen_w = 527\n",
    "screen_h = 296\n",
    "\n",
    "current = 0\n",
    "\n",
    "                                            \n",
    "                                            \n",
    "\n",
    "def compute_ppda(distance, h_res, v_res, screen_w, screen_h):\n",
    "    \"\"\"\n",
    "    Compute the number of pixels per degree of visual angle based on the experimental conditions.\n",
    "    \n",
    "    :param distance: int, the distance between the observer and the screen (in mm)\n",
    "    :param h_res: int, the horizontal resolution of the screen\n",
    "    :param v_res: int, the vertical resolution of the screen\n",
    "    :param screen_w: int, the width of the screen (in mm)\n",
    "    :param screen_h: int, the height of the screen (in mm)\n",
    "    :return horizontal_ppda: float, the number of pixel per degree of visual angle\n",
    "    \"\"\"\n",
    "    pxl_density_x = h_res / screen_w\n",
    "    pxl_density_y = v_res / screen_h\n",
    "    \n",
    "    d = 2 * distance * math.tan(np.deg2rad(0.5))\n",
    "    horizontal_ppda = d * ((pxl_density_x + pxl_density_y) / 2)\n",
    "    \n",
    "    return horizontal_ppda\n",
    "                                            \n",
    "ppda = compute_ppda(distance, h_res, v_res, screen_w, screen_h)\n",
    "\n",
    "for option in options:\n",
    "    for test_size in test_sizes:\n",
    "        for sigma in sigmas:\n",
    "            for factor in factors:\n",
    "                for gaussian_size in gaussian_sizes:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        for dropout in dropouts:\n",
    "                            for reg_term in reg_terms:\n",
    "                                for lr in learning_rates:\n",
    "                                    for patience in patiences:\n",
    "                                        for min_lr in min_lrs:\n",
    "                                            for grid_size in grid_sizes:\n",
    "    \n",
    "                                                def checkObserverRemembered(observer, image_path, base_dir):\n",
    "                                                    csv_file_path = os.path.join(base_dir, \"..\" ,\"hit_status.csv\")\n",
    "                                                    if not os.path.isfile(csv_file_path):\n",
    "                                                        print(\"Error: CSV file not found.\")\n",
    "                                                        return False\n",
    "                                                    df = pd.read_csv(csv_file_path)\n",
    "                                                    filtered_rows = df[(df['Setup Folder'] == observer) & (df['Image Path'] == image_path) & (df['Hit'] == 1)]\n",
    "                                                    if not filtered_rows.empty:\n",
    "                                                        return True\n",
    "                                                    else:\n",
    "                                                        return False\n",
    "    \n",
    "                                                def bin_fixations(fixation_map):\n",
    "                                                    global grid_size\n",
    "                                                    height, width = fixation_map.shape\n",
    "                                                    binned_map = np.zeros(grid_size)\n",
    "                                                \n",
    "                                                    bin_height = height // grid_size[0]\n",
    "                                                    bin_width = width // grid_size[1]\n",
    "                                                \n",
    "                                                    for i in range(grid_size[0]):\n",
    "                                                        for j in range(grid_size[1]):\n",
    "                                                            bin_area = fixation_map[i*bin_height:(i+1)*bin_height, j*bin_width:(j+1)*bin_width]\n",
    "                                                            binned_map[i, j] = np.sum(bin_area)\n",
    "                                                            #ili avg?\n",
    "                                                \n",
    "                                                    return binned_map\n",
    "                                                \n",
    "                                                def normalize_map(binned_map):\n",
    "                                                    return binned_map / np.sum(binned_map)\n",
    "                                                    #return binned_map\n",
    "                                                \n",
    "                                                def smooth_map(binned_map):\n",
    "                                                    global sigma\n",
    "                                                    return gaussian_filter(binned_map, sigma=sigma)\n",
    "                                                \n",
    "                                                def process_fixation_map(fixation_map):\n",
    "                                                    binned_map = bin_fixations(fixation_map)\n",
    "                                                    normalized_map = normalize_map(binned_map)\n",
    "                                                    smoothed_map = smooth_map(normalized_map)\n",
    "                                                    return smoothed_map\n",
    "                                                \n",
    "                                                def get_current_fixation_map(image_path, coordinates):\n",
    "                                                    image = cv2.imread(image_path)\n",
    "                                                    if image is None:\n",
    "                                                        print(f\"Image at {image_path} not found.\")\n",
    "                                                        return\n",
    "                                                \n",
    "                                                    coordinates = coordinates[0:120]\n",
    "                                                  \n",
    "                                                    fixation_map = np.zeros((1080, 1920), dtype=np.float32)\n",
    "                                                \n",
    "                                                    # Convert coordinates to pixel coordinates and update the saliency map\n",
    "                                                    for x_norm, y_norm in coordinates:\n",
    "                                                        # Scale normalized coordinates to pixel coordinates for the 1920x1080 screen\n",
    "                                                        x = int(((x_norm + 1) / 2 ) * 1920)  # Scaling from (-1, 1) to (0, 1920) range\n",
    "                                                        y = int((y_norm + 0.5) * 1080) # Scaling from (-0.5, 0.5) to (0, 1080) range\n",
    "                                                        # Update the saliency map if coordinates are within the screen\n",
    "                                                        if 0 <= x < 1920 and 0 <= y < 1080:\n",
    "                                                            fixation_map[y, x] += 1 \n",
    "\n",
    "                                                    fixation_map = cv2.GaussianBlur(fixation_map, gaussian_size, 0)\n",
    "                                                    # Crop the saliency map to the 700x700 region\n",
    "                                                    fixation_map = fixation_map[190:890, 610:1310]\n",
    "                                                    # flip the Y coordinates\n",
    "                                                    fixation_map = np.flipud(fixation_map)\n",
    "                                                    return fixation_map\n",
    "                                                \n",
    "                                                def normalize_fixation_map(fixation_map):\n",
    "                                                    min_val = np.min(fixation_map)\n",
    "                                                    max_val = np.max(fixation_map)\n",
    "                                                    normalized_fixation_map = (fixation_map - min_val) / (max_val - min_val) * 255\n",
    "                                                    return normalized_fixation_map\n",
    "                                                \n",
    "                                                # 90experiments folder\n",
    "                                                base_dir = os.path.abspath(os.path.join(os.getcwd(),\"..\", \"90experiments\"))\n",
    "                                                \n",
    "                                                fixation_maps = {}  # Dictionary to store fixation maps for each imagePath\n",
    "                                                \n",
    "                                                \n",
    "                                                for folder in os.listdir(base_dir):\n",
    "                                                    folder_path = os.path.join(base_dir, folder)\n",
    "                                                    if not os.path.isdir(folder_path):\n",
    "                                                        continue\n",
    "                                                    match = re.search(r'\\d{1,2}$', folder)\n",
    "                                                    if match:\n",
    "                                                        observer = int(match.group())\n",
    "\n",
    "                                                    if(observer == 1 or observer == 2 or observer == 49 or observer == 50 or observer == 5):\n",
    "                                                        continue\n",
    "\n",
    "                                                    csv_file_path = os.path.join(folder_path, \"eye_tracker_data.csv\")\n",
    "                                                    if not os.path.isfile(csv_file_path):\n",
    "                                                        continue\n",
    "                                                    data = pd.read_csv(csv_file_path)\n",
    "                                                \n",
    "                                                    filtered_data = data[data['ImagePath'].str.startswith('targetImages')]\n",
    "                                                    \n",
    "                                                    uniqueImagePaths = []\n",
    "                                                    delete_rows = []\n",
    "                                                \n",
    "                                                    #get only the eye-tracking data from the first viewing\n",
    "                                                    index = 0\n",
    "                                                    \n",
    "                                                    row = filtered_data.iloc[index]\n",
    "                                                    while len(uniqueImagePaths) < 10:\n",
    "                                                        row = filtered_data.iloc[index]\n",
    "                                                        if(row['ImagePath'] not in uniqueImagePaths):\n",
    "                                                            uniqueImagePaths.append(row['ImagePath'])\n",
    "                                                            lastImagePath = row['ImagePath']\n",
    "                                                            index +=1\n",
    "                                                        elif(row['ImagePath'] in uniqueImagePaths):\n",
    "                                                            index += 1    \n",
    "                                                    row = filtered_data.iloc[index]\n",
    "                                                \n",
    "                                                    while(row['ImagePath'] == lastImagePath):\n",
    "                                                        index +=1\n",
    "                                                        row = filtered_data.iloc[index]\n",
    "                                                \n",
    "                                                    filtered_data.reset_index(drop=True, inplace=True)\n",
    "                                                    filtered_data = filtered_data.iloc[:index].copy()\n",
    "                                                    \n",
    "                                                    grouped = filtered_data.groupby('ImagePath')\n",
    "                                                \n",
    "                                                    # Generate and save fixation maps for each image in the current folder\n",
    "                                                    for image_path, group in grouped:\n",
    "                                                        # Construct full image path by going one directory back from base_dir\n",
    "                                                        full_image_path = os.path.abspath(os.path.join(base_dir, \"..\", image_path))\n",
    "                                                        full_image_path = full_image_path.replace('\\\\', '/')\n",
    "                                                \n",
    "                                                        #check if current observer has remembered this image, if not, continue\n",
    "                                                        if(not checkObserverRemembered(observer, image_path, base_dir)):\n",
    "                                                            continue\n",
    "                                                        \n",
    "                                                        # Extract coordinates\n",
    "                                                        coordinates = group[['PosX', 'PosY']].values\n",
    "                                                \n",
    "                                                        current_fixation_map = get_current_fixation_map (full_image_path, coordinates)\n",
    "                                                        if(np.all(current_fixation_map == 0)):\n",
    "                                                            continue\n",
    "                                                \n",
    "                                                        current_fixation_map_20x20 = process_fixation_map(current_fixation_map)\n",
    "                                                        current_fixation_map_20x20 = normalize_fixation_map(current_fixation_map_20x20)\n",
    "                                                        \n",
    "                                                        #current_fixation_map_20x20 = (current_fixation_map)\n",
    "                                                        #add to dictionary or update it\n",
    "                                                        if image_path not in fixation_maps:\n",
    "                                                            fixation_maps[image_path] = [current_fixation_map_20x20]\n",
    "                                                        else:\n",
    "                                                            fixation_maps[image_path].append(current_fixation_map_20x20)\n",
    "                                                            \n",
    "                                                # Flatten the fixation maps and standardize them\n",
    "                                                all_fixation_maps = []\n",
    "                                                labels = []\n",
    "                                                \n",
    "                                                for image_path, maps in fixation_maps.items():\n",
    "                                                    for fixation_map in maps:\n",
    "                                                        all_fixation_maps.append(fixation_map.flatten())\n",
    "                                                        labels.append(image_path)\n",
    "                                                \n",
    "                                                X = np.array(all_fixation_maps)\n",
    "                                                y = np.array(labels)\n",
    "          \n",
    "                                                #training\n",
    "                                                from keras.applications import VGG16, MobileNetV2\n",
    "                                                from tensorflow.keras.models import Sequential\n",
    "                                                from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "                                                from tensorflow.keras.optimizers import Adam\n",
    "                                                from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "                                                from sklearn.metrics import classification_report, accuracy_score\n",
    "                                                from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "                                                from tensorflow.keras.regularizers import l2\n",
    "                                                from imblearn.over_sampling import SMOTE\n",
    "                                                import collections\n",
    "                                                import numpy as np\n",
    "                                                import matplotlib.pyplot as plt\n",
    "                                                import json\n",
    "                                                from sklearn.svm import SVC\n",
    "                                                from sklearn.ensemble import RandomForestClassifier\n",
    "                                                from sklearn.preprocessing import LabelEncoder\n",
    "                                                from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "                                                from keras.preprocessing.image import img_to_array, array_to_img\n",
    "                                                import joblib \n",
    "\n",
    "    \n",
    "                                                def save_model(model, model_save_path, option):\n",
    "                                                    # Check if the model is a Keras model by checking if it has a 'save' method\n",
    "                                                    if hasattr(model, 'save'):\n",
    "                                                        model.save(model_save_path)\n",
    "                                                    else:\n",
    "                                                        # For scikit-learn models, use joblib to save\n",
    "                                                        joblib.dump(model, model_save_path)\n",
    "                                                \n",
    "                                                trainings = 30\n",
    "                                                \n",
    "                                                for i in range(trainings):\n",
    "                                                    X = X.reshape(-1, grid_size[0], grid_size[1], 1)\n",
    "                                                \n",
    "                                                    label_encoder = LabelEncoder()\n",
    "                                                    y_encoded = label_encoder.fit_transform(y)\n",
    "                                                    label_names = label_encoder.classes_\n",
    "                                                    \n",
    "                                                    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=test_size, stratify=y_encoded)\n",
    "                                                    \n",
    "                                                    y_train_categorical = to_categorical(y_train, num_classes=len(label_encoder.classes_))\n",
    "                                                    y_test_categorical = to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "\n",
    "                                                    if(option == \"mlp\"):\n",
    "                                                        # Define the MLP model\n",
    "                                                        model = Sequential([\n",
    "                                                            Input(shape=(grid_size[0], grid_size[1], 1)),\n",
    "                                                            Flatten(),\n",
    "                                                            Dense(512, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                            BatchNormalization(),\n",
    "                                                            Dropout(dropout),\n",
    "                                                            Dense(256, activation='relu', kernel_regularizer=l2(reg_term)),\n",
    "                                                            BatchNormalization(),\n",
    "                                                            Dropout(dropout),\n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "                                                    elif(option == \"resnet\"):\n",
    "                                                        \n",
    "                                                        input_size = (32, 32)\n",
    "                                                        X_train = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_train])\n",
    "                                                        X_test = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_test])\n",
    "        \n",
    "                                                        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "        \n",
    "                                                        model = Sequential([\n",
    "                                                            base_model,\n",
    "                                                            GlobalAveragePooling2D(),\n",
    "                                                            Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "                                                            Dropout(0.5),\n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "                                                    elif(option == \"vgg\"):\n",
    "                                                        # Define the input size\n",
    "                                                        input_size = (32, 32)\n",
    "                                                        \n",
    "                                                        # Convert X_train and X_test to have 3 channels and resize them\n",
    "                                                        X_train = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_train])\n",
    "                                                        X_test = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_test])\n",
    "                                                        \n",
    "                                                        # Load the VGG16 model without the top layers and specify input shape\n",
    "                                                        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "                                                        \n",
    "                                                        # Build the sequential model\n",
    "                                                        model = Sequential([\n",
    "                                                            base_model,\n",
    "                                                            GlobalAveragePooling2D(),\n",
    "                                                            Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "                                                            Dropout(0.5),\n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "\n",
    "                                                    elif(option == \"mobilenetv2\"):\n",
    "                                                        # Define the input size\n",
    "                                                        input_size = (32, 32)\n",
    "                                                        \n",
    "                                                        # Convert X_train and X_test to have 3 channels and resize them\n",
    "                                                        X_train = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_train])\n",
    "                                                        X_test = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)) for img in X_test])\n",
    "                                                        \n",
    "                                                        # Load the MobileNetV2 model without the top layers and specify input shape\n",
    "                                                        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "                                                        \n",
    "                                                        # Build the sequential model\n",
    "                                                        model = Sequential([\n",
    "                                                            base_model,\n",
    "                                                            GlobalAveragePooling2D(),\n",
    "                                                            Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "                                                            Dropout(0.5),\n",
    "                                                            Dense(len(label_encoder.classes_), activation='softmax')\n",
    "                                                        ])\n",
    "                                                    elif option == \"svm\":\n",
    "                                                        input_size = (32, 32)\n",
    "                                                        X_train_flat = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)).flatten() for img in X_train])\n",
    "                                                        X_test_flat = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)).flatten() for img in X_test])\n",
    "                                                    \n",
    "                                                        label_encoder = LabelEncoder()\n",
    "                                                        y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "                                                        y_test_encoded = label_encoder.transform(y_test)\n",
    "                                                    \n",
    "                                                        model = SVC(kernel='linear', C=1.0, probability=True)\n",
    "                                                        model.fit(X_train_flat, y_train_encoded)\n",
    "                                                    \n",
    "                                                        # Predictions\n",
    "                                                        y_pred_prob = model.predict_proba(X_test_flat)\n",
    "                                                        y_pred = model.predict(X_test_flat)\n",
    "                                                    \n",
    "                                                    elif option == \"randomforest\":\n",
    "                                                        input_size = (32, 32)\n",
    "                                                        X_train_flat = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)).flatten() for img in X_train])\n",
    "                                                        X_test_flat = np.array([img_to_array(array_to_img(np.repeat(img, 3, axis=2)).resize(input_size)).flatten() for img in X_test])\n",
    "                                                    \n",
    "                                                        label_encoder = LabelEncoder()\n",
    "                                                        y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "                                                        y_test_encoded = label_encoder.transform(y_test)\n",
    "                                                    \n",
    "                                                        model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "                                                        model.fit(X_train_flat, y_train_encoded)\n",
    "                                                    \n",
    "                                                        # Predictions\n",
    "                                                        y_pred_prob = model.predict_proba(X_test_flat)\n",
    "                                                        y_pred = model.predict(X_test_flat)\n",
    "                                                    \n",
    "                                                    elif option == \"rusboost\":\n",
    "                                                        # Placeholder for RUSBoost implementation\n",
    "                                                        # Implement as needed for your specific case\n",
    "                                                        pass\n",
    "                                                    \n",
    "                                                    # Compile the model only for neural networks\n",
    "                                                    if option in [\"mlp\", \"resnet\", \"vgg\", \"mobilenetv2\"]:\n",
    "                                                        model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy',\n",
    "                                                                      metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)])\n",
    "                                                    \n",
    "                                                        # Callbacks for learning rate adjustment and early stopping\n",
    "                                                        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, min_lr=min_lr)\n",
    "                                                        early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "                                                        model_checkpoint = ModelCheckpoint(os.path.join(results_folder, 'best_model_brute_force.keras'), monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "                                                    \n",
    "                                                        # Train the model\n",
    "                                                        history = model.fit(X_train, y_train_categorical,\n",
    "                                                                            validation_data=(X_test, y_test_categorical),\n",
    "                                                                            epochs=1000,\n",
    "                                                                            callbacks=[reduce_lr, early_stopping, model_checkpoint],\n",
    "                                                                            # class_weight=class_weights,\n",
    "                                                                            batch_size=batch_size,\n",
    "                                                                            verbose=0\n",
    "                                                                            )\n",
    "                                                    \n",
    "                                                        # Evaluate the model\n",
    "                                                        y_pred_prob = model.predict(X_test, verbose=0)\n",
    "                                                        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "                                                    else:\n",
    "                                                        # For non-neural network models like SVM and RandomForest\n",
    "                                                        # We assume y_pred and y_pred_prob are already obtained above\n",
    "                                                        y_pred = model.predict(X_test_flat)\n",
    "                                                        y_pred_prob = model.predict_proba(X_test_flat)\n",
    "                                                    \n",
    "                                                    # Calculate accuracy\n",
    "                                                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                                                    if((not option in model_accuracies) or accuracy > model_accuracies[option]):\n",
    "                                                        model_accuracies[option] = accuracy\n",
    "                                                    if(option in [\"mlp\", \"resnet\", \"vgg\", \"mobilenetv2\"]):\n",
    "                                                        top_3_accuracy = history.history['val_top_k_categorical_accuracy'][-1]\n",
    "                                                    else:\n",
    "                                                        top_3_accuracy = 0\n",
    "                                                    f1 = f1_score(y_test, y_pred, average='macro')  # You can use 'micro' or 'weighted' based on your needs\n",
    "                                                    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                                                    per_class_accuracy = np.mean(conf_matrix.diagonal() / conf_matrix.sum(axis=1))\n",
    "                                                    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "                                                  \n",
    "                                                        \n",
    "                                                    if(accuracy > best_accuracy):\n",
    "                                                        model_save_path = os.path.join(results_folder, 'best_model.keras')  # For Keras models\n",
    "                                                        model_save_path_sklearn = os.path.join(results_folder, 'best_model_sklearn.pkl')  # For scikit-learn models\n",
    "\n",
    "                                                        best_accuracy = accuracy\n",
    "                                                        best_params = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest best accuracy: \", best_accuracy)\n",
    "                                                        print(\"Params: \", best_params)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Best accuracy: {best_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'best_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "                                                        #save_model(model, model_save_path if option in [\"mlp\", \"resnet\", \"vgg\", \"mobilenetv2\"] else model_save_path_sklearn, option)\n",
    "\n",
    "                                                            \n",
    "                                                    if(top_3_accuracy > best_top3_accuracy):\n",
    "                                                        best_top3_accuracy = top_3_accuracy\n",
    "                                                        best_params_top3 = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest top3 best accuracy: \", best_top3_accuracy)\n",
    "                                                        print(\"Params top3: \", best_params_top3)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_top3_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Top 3 accuracy: {best_top3_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best top3 parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params_top3, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'top3_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "                                                        #save_model(model, model_save_path if option in [\"mlp\", \"resnet\", \"vgg\", \"mobilenetv2\"] else model_save_path_sklearn, option)\n",
    "\n",
    "    \n",
    "                                                    if(f1 > best_f1_accuracy):\n",
    "                                                        best_f1_accuracy = f1\n",
    "                                                        best_params_f1 = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest f1 best accuracy: \", best_f1_accuracy)\n",
    "                                                        print(\"Params f1: \", best_params_f1)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_f1_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Top f1 accuracy: {best_f1_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best f1 parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params_f1, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'f1_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "    \n",
    "                                                    if(per_class_accuracy > best_per_class_accuracy):\n",
    "                                                        best_per_class_accuracy = per_class_accuracy\n",
    "                                                        best_params_per_class = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest per class best accuracy: \", best_per_class_accuracy)\n",
    "                                                        print(\"Params per class: \", best_params_per_class)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_per_class_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Top per_class accuracy: {best_per_class_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best per class parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params_per_class, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'per_class_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "    \n",
    "                                                    if(balanced_accuracy > best_balanced_accuracy):\n",
    "                                                        best_balanced_accuracy = balanced_accuracy\n",
    "                                                        best_params_balanced = {\n",
    "                                                                       'sigma':sigma, \n",
    "                                                                       'grid_size':grid_size, \n",
    "                                                                       'gaussian_size':gaussian_size,\n",
    "                                                                       'batch_size':batch_size,\n",
    "                                                                       'dropout':dropout,\n",
    "                                                                       'reg_term':reg_term,\n",
    "                                                                       'lr':lr,\n",
    "                                                                       'patience':patience,\n",
    "                                                                       'min_lr':min_lr,\n",
    "                                                                       'factor':factor,\n",
    "                                                                       'test_size': test_size,\n",
    "                                                                        'model' : option}\n",
    "                                                        print(\"Newest balanced best accuracy: \", best_balanced_accuracy)\n",
    "                                                        print(\"Params balanced accuracy: \", best_params_balanced)\n",
    "                                                        # Save the best model, accuracy and top-3 accuracy\n",
    "                                                        with open(os.path.join(results_folder, \"best_accuracy_MLP_search_balanced_accuracy.txt\"), \"w\") as f:\n",
    "                                                            f.write(f\"Top balanced accuracy: {best_balanced_accuracy:.4f}\\n\")\n",
    "                                                            f.write(\"Best balanced accuracy parameters:\\n\")\n",
    "                                                            f.write(json.dumps(best_params_balanced, indent=4))\n",
    "                                                        # Define the path to save the model\n",
    "                                                        '''model_save_path = os.path.join(results_folder, 'balanced_accuracy_model.keras')\n",
    "                                                        # Save the model\n",
    "                                                        model.save(model_save_path)'''\n",
    "                                                    current += 1\n",
    "                                                    print(\"Current: \", current)\n",
    "                                                # Clear large data structures\n",
    "                                                del fixation_maps, all_fixation_maps, X, y\n",
    "                                                gc.collect()\n",
    "                                                \n",
    "                                                # Clear Keras session state\n",
    "                                                tf.keras.backend.clear_session()\n",
    "    \n",
    "                                                # Additionally, delete the model and history to ensure they don't consume memory\n",
    "                                                del model, X_train, X_test, y_train, y_test, y_train_categorical, y_test_categorical, y_pred_prob, y_pred, conf_matrix\n",
    "                                                gc.collect()\n",
    "\n",
    "\n",
    "#print(\"FINAL Best accuracy: \", best_accuracy)\n",
    "#print(\"FINAL Params: \", best_params)\n",
    "\n",
    "# Plotting accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_accuracies.keys(), model_accuracies.values(), color='skyblue')\n",
    "plt.xlabel('Model Option')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Each Model Option')\n",
    "plt.ylim(0, 1)  # Since accuracy is a fraction between 0 and 1\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Annotate each bar with the accuracy value\n",
    "for i, (model, acc) in enumerate(model_accuracies.items()):\n",
    "    plt.text(i, acc + 0.01, f'{acc:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('model_accuracies.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b8637-3f02-4e82-8574-dd97cda889bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
